{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "#Run with python 2.7\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import pickle\n",
    "import sys\n",
    "% matplotlib inline\n",
    "\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "from george import kernels\n",
    "import george\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../code\")\n",
    "# Import code\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "from hierarchicalmodel import *\n",
    "from rasle import *\n",
    "from preprocessing import *\n",
    "from GPFit import *\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "figSize  = (12, 8)\n",
    "fontSize = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Section Needs to be changed each time\n",
    "nFeatures = 7 # Number of features considered\n",
    "\n",
    "# All Labels of the different variabe stars\n",
    "true_class_1=1;true_class_2=2;true_class_3=3;true_class_4=4;true_class_5=5;true_class_6=6;true_class_7=7;\\\n",
    "true_class_8=8;true_class_9=9;true_class_10=10;true_class_11=11;true_class_12=12;true_class_13=13\n",
    "\n",
    "eclipsing_label = 20;rotational_label = 21;pulsating_label = 22;RR_Lyrae_label = 23; LPV_label = 24;\\\n",
    "delta_scuti_label = 25; cepheids_label   = 26\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA AUGMENTATION AND FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACEP train has (107, 2)\n",
      "Cep-II train has (107, 2)\n",
      "ACEP test has (46, 2)\n",
      "Cep-II test has (46, 2)\n",
      "The number of sample in Class 0 is 107 and is now augmented by 2 times. The augmented samples are 214\n",
      "The number of sample in Class 1 is 107 and is now augmented by 2 times. The augmented samples are 214\n"
     ]
    }
   ],
   "source": [
    "data_preparation = True\n",
    "data_dir_train = '../data/training_phase_lc/'\n",
    "data_dir_test  = '../data/test_phase_lc/'\n",
    "\n",
    "# Loading the photometry data to get the filenames and their respective classes\n",
    "ascii_data  = pd.read_csv('../data/catalogue/Ascii_SSS_Per_Table.txt',delim_whitespace=True,names = [\"SSS_ID\", \"File_Name\", \"RA\", \"Dec\", \"Period\", \"V_CSS\", \"Npts\", \"V_amp\", \"Type\", \"Prior_ID\", \"No_Name1\", 'No_Name2'])\n",
    "ascii_files = ascii_data[['File_Name', 'Type']] # Selecting only the filename and the type of stars\n",
    "\n",
    "'''\n",
    "Peforming a downsammpling of Type 5- We downsample class 5 from 18000 to 4509. And we remove class 11 and 13.\n",
    "'''\n",
    "\n",
    "type_11     = ascii_files[ascii_files.Type==true_class_11]\n",
    "type_13     = ascii_files[ascii_files.Type==true_class_13]\n",
    "\n",
    "ascii_files = ascii_files.drop(type_11.index)\n",
    "ascii_files = ascii_files.drop(type_13.index)\n",
    "\n",
    "\n",
    "\n",
    "period_data                   = ascii_data[['Period', 'File_Name', 'Type']]# Use for Test set Period\n",
    "periods                       = ascii_data[['File_Name', 'Period']] # Use for Test set Period\n",
    "update_ascii_period           = pd.DataFrame(periods.File_Name.astype(str) + '_2') # Use for Training set Period\n",
    "update_ascii_period['Period'] = periods.Period\n",
    "\n",
    "if data_preparation: \n",
    "    X_training = phase_data_sets(data_dir_train,ascii_files)\n",
    "    X_testing  = phase_data_sets(data_dir_test,ascii_files) \n",
    "\n",
    "    data_columns = ['magnitude', 'time']\n",
    "    features     = ['Skew', 'Mean', 'Std', 'SmallKurtosis', 'Amplitude', 'Meanvariance']\n",
    "\n",
    "\n",
    "    RRab_train        = stars_label(X_training, true_class_1, column_name='Type')\n",
    "    RRc_train         = stars_label(X_training, true_class_2, column_name='Type') \n",
    "    RRd_train         = stars_label(X_training, true_class_3, column_name='Type')\n",
    "    blazhko_train     = stars_label(X_training, true_class_4, column_name='Type')\n",
    "    contact_Bi_train  = stars_label(X_training, true_class_5, column_name='Type')\n",
    "    semi_det_Bi_train = stars_label(X_training, true_class_6, column_name='Type')\n",
    "    rot_train         = stars_label(X_training, true_class_7, column_name='Type')\n",
    "    LPV_train         = stars_label(X_training, true_class_8, column_name='Type')\n",
    "    delta_scuti_train = stars_label(X_training, true_class_9, column_name='Type')\n",
    "    ACEP_train        = stars_label(X_training, true_class_10, column_name='Type')\n",
    "    cep_ii_train      = stars_label(X_training, true_class_12, column_name='Type')\n",
    "\n",
    "    RRab_test        = stars_label(X_testing, true_class_1, column_name='Type')\n",
    "    RRc_test         = stars_label(X_testing, true_class_2, column_name='Type') \n",
    "    RRd_test         = stars_label(X_testing, true_class_3, column_name='Type')\n",
    "    blazhko_test     = stars_label(X_testing, true_class_4, column_name='Type')\n",
    "    contact_Bi_test  = stars_label(X_testing, true_class_5, column_name='Type')\n",
    "    semi_det_Bi_test = stars_label(X_testing, true_class_6, column_name='Type')\n",
    "    rot_test         = stars_label(X_testing, true_class_7, column_name='Type')\n",
    "    LPV_test         = stars_label(X_testing, true_class_8, column_name='Type')\n",
    "    delta_scuti_test = stars_label(X_testing, true_class_9, column_name='Type')\n",
    "    ACEP_test        = stars_label(X_testing, true_class_10, column_name='Type')\n",
    "    cep_ii_test      = stars_label(X_testing, true_class_12, column_name='Type')\n",
    "       \n",
    "    '-----------------------------------------------------------------------------'\n",
    "                                    # FIRST LAYER\n",
    "    '-----------------------------------------------------------------------------'\n",
    "    training_data_FL, testing_data_FL, y_FL_training_counts = first_layer(contact_Bi_train, semi_det_Bi_train,rot_train,RRab_train, RRc_train, RRd_train, blazhko_train, LPV_train, delta_scuti_train, ACEP_train, cep_ii_train,\\\n",
    "                                                            contact_Bi_test, semi_det_Bi_test,rot_test,RRab_test, RRc_test, RRd_test, blazhko_test, LPV_test, delta_scuti_test, ACEP_test, cep_ii_test,\\\n",
    "                                                            eclipsing_label,rotational_label,pulsating_label)\n",
    "\n",
    "    # This part is calculating the number of times each class need to be augmented    \n",
    "    ns_FL = num_augmentation(nAugmentation=17000, y_training_counts=y_FL_training_counts)#17000\n",
    "    print(ns_FL)\n",
    "\n",
    "\n",
    "    # Each class is augmented using their respective number of samples and features are extracted\n",
    "    augmentation_data, feature_file = GP_augmentation_and_featureExtraction(data_dir=data_dir_train, \\\n",
    "                                          data_ = training_data_FL,data_columns=data_columns,period_data=period_data,\\\n",
    "                                          features=features,update_ascii_period=update_ascii_period,\\\n",
    "                                          number_of_samples=ns_FL,save_folder_training = '../data/GP/HC/layer1_EclRotPul/training_set/')\n",
    "\n",
    "    # Features from each class from the test set are extracted and save in a single \n",
    "    feature_file_testSet    = GP_feature_extraction_test_set(data_dir=data_dir_test,period_data=period_data,periods=periods,\\\n",
    "                                  X_testing=testing_data_FL,data_columns=data_columns,\\\n",
    "                                  features=features,save_folder_test= '../data/GP/HC/layer1_EclRotPul/test_set/')\n",
    "\n",
    "#     '-------------------------------------------------------------------------------'\n",
    "#                             # SECOND LAYER ECLIPSING BINARY\n",
    "#     '-------------------------------------------------------------------------------'\n",
    "    training_data_SL_EB, testing_data_SL_EB, y_SL_EB_training_counts = second_layer_EB(contact_Bi_train,semi_det_Bi_train,contact_Bi_test,semi_det_Bi_test,true_class_5,true_class_6)\n",
    "\n",
    "\n",
    "    # This part is calculating the number of times each class need to be augmented    \n",
    "    ns_SL_EB = num_augmentation(nAugmentation=10000, y_training_counts=y_SL_EB_training_counts)#10000\n",
    "    print(ns_SL_EB)\n",
    "\n",
    "\n",
    "    # Each class is augmented using their respective number of samples and features are extracted\n",
    "    augmentation_data_SL_EB, feature_file_SL_EB = GP_augmentation_and_featureExtraction(data_dir=data_dir_train, \\\n",
    "                                          data_ = training_data_SL_EB,data_columns=data_columns,period_data=period_data,\\\n",
    "                                          features=features,update_ascii_period=update_ascii_period,\\\n",
    "                                          number_of_samples=ns_SL_EB,save_folder_training = '../data/GP/HC/layer2_EB/training_set/')\n",
    "\n",
    "    # Features from each class from the test set are extracted and save in a single \n",
    "    feature_file_testSet_SL_EB    = GP_feature_extraction_test_set(data_dir=data_dir_test,period_data=period_data,periods=periods,\\\n",
    "                                  X_testing=testing_data_SL_EB,data_columns=data_columns,\\\n",
    "                                  features=features,save_folder_test= '../data/GP/HC/layer2_EB/test_set/')\n",
    "\n",
    "#     '-----------------------------------------------------------------------------'\n",
    "#                         # SECOND LAYER RR LYRAE PULSATING LPV CEPHEIDS\n",
    "#     '-----------------------------------------------------------------------------'\n",
    "    training_data_SL_RLCD, testing_data_SL_RLCD, y_SL_RLCD_training_counts = second_layer_RLCD(RRab_train,RRc_train,RRd_train,blazhko_train,LPV_train,ACEP_train,cep_ii_train,delta_scuti_train,\\\n",
    "                                                                            RRab_test,RRc_test,RRd_test,blazhko_test,LPV_test,ACEP_test, cep_ii_test,delta_scuti_test,RR_Lyrae_label,\\\n",
    "                                                                            LPV_label,cepheids_label,delta_scuti_label)\n",
    "\n",
    "\n",
    "\n",
    "    # This part is calculating the number of times each class need to be augmented    \n",
    "    ns_SL_RLCD = num_augmentation(nAugmentation=17000, y_training_counts=y_SL_RLCD_training_counts)#17000\n",
    "    print(ns_SL_RLCD)\n",
    "\n",
    "\n",
    "    # Each class is augmented using their respective number of samples and features are extracted\n",
    "    augmentation_data_SL_RLCD, feature_file_SL_RLCD = GP_augmentation_and_featureExtraction(data_dir=data_dir_train, \\\n",
    "                                          data_ = training_data_SL_RLCD,data_columns=data_columns,\\\n",
    "                                          features=features,update_ascii_period=update_ascii_period,period_data=period_data,\\\n",
    "                                          number_of_samples=ns_SL_RLCD,save_folder_training = '../data/GP/HC/layer2_RLCD/training_set/')\n",
    "\n",
    "    # Features from each class from the test set are extracted and save in a single \n",
    "    feature_file_testSet_SL_RLCD    = GP_feature_extraction_test_set(data_dir=data_dir_test,period_data=period_data,periods=periods,\\\n",
    "                                  X_testing=testing_data_SL_RLCD,data_columns=data_columns,\\\n",
    "                                  features=features,save_folder_test= '../data/GP/HC/layer2_RLCD/test_set/')\n",
    "\n",
    "#     '-----------------------------------------------------------------------------'\n",
    "#                     # THIRD LAYER RR LYRAE: RRab, RRc, RRd, Blazhko\n",
    "#     '-----------------------------------------------------------------------------'\n",
    "    training_data_TL_RRLyrae, testing_data_TL_RRLyrae, y_TL_RRLyrae_training_counts = third_layer_RRLyrae(RRab_train,RRc_train,RRd_train,blazhko_train,RRab_test,RRc_test,RRd_test,blazhko_test,\\\n",
    "                                                                                      true_class_1,true_class_2,true_class_3,true_class_4)\n",
    "\n",
    "\n",
    "    # This part is calculating the number of times each class need to be augmented    \n",
    "    ns_TL_RRLyrae = num_augmentation(nAugmentation=10000, y_training_counts=y_TL_RRLyrae_training_counts)#10000\n",
    "    print(ns_TL_RRLyrae)\n",
    "\n",
    "\n",
    "    # Each class is augmented using their respective number of samples and features are extracted\n",
    "    augmentation_data_TL_RRLyrae, feature_file_TL_RRLyrae = GP_augmentation_and_featureExtraction(data_dir=data_dir_train, \\\n",
    "                                          data_ = training_data_TL_RRLyrae,data_columns=data_columns,period_data=period_data,\\\n",
    "                                          features=features,update_ascii_period=update_ascii_period,\\\n",
    "                                          number_of_samples=ns_TL_RRLyrae,save_folder_training = '../data/GP/HC/layer3_RRLyrae/training_set/')\n",
    "\n",
    "    # Features from each class from the test set are extracted and save in a single \n",
    "    feature_file_testSet_TL_RRLyrae    = GP_feature_extraction_test_set(data_dir=data_dir_test,period_data=period_data,periods=periods,\\\n",
    "                                  X_testing=testing_data_TL_RRLyrae,data_columns=data_columns,\\\n",
    "                                  features=features,save_folder_test= '../data/GP/HC/layer3_RRLyrae/test_set/')\n",
    "\n",
    "    '-----------------------------------------------------------------------------'\n",
    "                            # THIRD LAYER Cepheids: ACEP and Cep-II\n",
    "    '-----------------------------------------------------------------------------'\n",
    "    training_data_TL_cep, testing_data_TL_cep, y_TL_cep_training_counts = third_layer_Cepheids(ACEP_train,cep_ii_train,ACEP_test,cep_ii_test,true_class_10,true_class_12)\n",
    "\n",
    "    # This part is calculating the number of times each class need to be augmented    \n",
    "    ns_TL_cep = num_augmentation(nAugmentation=5000, y_training_counts=y_TL_cep_training_counts)#5000\n",
    "\n",
    "\n",
    "    # Each class is augmented using their respective number of samples and features are extracted\n",
    "    augmentation_data_TL_cep, feature_file_TL_cep = GP_augmentation_and_featureExtraction(data_dir=data_dir_train, \\\n",
    "                                          data_ = training_data_TL_cep,data_columns=data_columns,period_data=period_data,\\\n",
    "                                          features=features,update_ascii_period=update_ascii_period,\\\n",
    "                                          number_of_samples=ns_TL_cep,save_folder_training = '../data/GP/HC/layer3_Cepheids/training_set/')\n",
    "\n",
    "    # Features from each class from the test set are extracted and save in a single \n",
    "    feature_file_testSet_TL_cep    = GP_feature_extraction_test_set(data_dir=data_dir_test,period_data=period_data,periods=periods,\\\n",
    "                                  X_testing=testing_data_TL_cep,data_columns=data_columns,\\\n",
    "                                  features=features,save_folder_test= '../data/GP/HC/layer3_Cepheids/test_set/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
