{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import pickle\n",
    "#plt.switch_backend('agg')\n",
    "% matplotlib inline\n",
    "\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import FATS\n",
    "\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "figSize  = (12, 8)\n",
    "fontSize = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from scipy import interp\n",
    "from itertools import cycle, islice\n",
    "#from keras.utils import np_utils\n",
    "\n",
    "# Some preprocessing utilities\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.manifold.t_sne import TSNE\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# The different classifiers\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalisation(x_train,x_test):\n",
    "    scaler                = StandardScaler().fit(x_train.iloc[:,0:nFeatures])\n",
    "    X_train_normalisation = pd.DataFrame(scaler.transform(x_train.iloc[:,0:nFeatures]))\n",
    "    y_train_label         = x_train.True_class_labels\n",
    "    filename_train        = x_train.File_Name\n",
    "\n",
    "    X_test_normalisation = pd.DataFrame(scaler.transform(x_test.iloc[:,0:nFeatures]))\n",
    "    y_test_label         = x_test.True_class_labels\n",
    "    filename_test        = x_test.File_Name\n",
    "    \n",
    "    # A check to see whether the mean of x_train and X_test are ~ 0 with std 1.0\n",
    "#     print(X_train_normalisation.mean(axis=0))\n",
    "#     print(X_train_normalisation.std(axis=0))\n",
    "#     print(X_test_normalisation.mean(axis=0))\n",
    "#     print(X_test_normalisation.std(axis=0))\n",
    "    \n",
    "    return X_train_normalisation, y_train_label, filename_train, X_test_normalisation,\\\n",
    "           y_test_label, filename_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gridsearch(X_train,y_train,classifer, param_grid, n_iter, cv, filename='./results'):\n",
    "    grid  = RandomizedSearchCV(classifer, param_grid, n_iter = n_iter, cv = cv, scoring = \"accuracy\", n_jobs = -1,random_state=1)\n",
    "    grid.fit(X_train,y_train)\n",
    "    opt_parameters = grid.best_params_\n",
    "    print(grid.best_params_)\n",
    "    \n",
    "    params_file = open(filename, 'w')\n",
    "    params_file.write(str(grid.best_params_))\n",
    "    params_file.close()\n",
    "    return opt_parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_save(classifier_optimize, X_train, y_train, filename_model, save_model=False):\n",
    "    fit_model      = classifier_optimize.fit(X_train, y_train)\n",
    "    \n",
    "    if save_model:\n",
    "        pickle.dump(fit_model, open(filename_model, 'wb'))\n",
    "        \n",
    "    return fit_model\n",
    "\n",
    "def model_fit(fit_model, filename_model, X_train, y_train, X_test, y_test, classifier_model='Random Forest Classifier',classes=[\"Type 1\" , \"Type 2\"], filename ='./results/',load_model=False):\n",
    "    if load_model:\n",
    "        fit_model      = pickle.load(open(filename_model, 'rb'))\n",
    "    \n",
    "    else:\n",
    "        fit_model = fit_model\n",
    "        \n",
    "    ypred          = fit_model.predict(X_test)\n",
    "    probability    = fit_model.predict_proba(X_test)\n",
    "    accuracy       = accuracy_score(y_test, ypred)\n",
    "    MCC            = matthews_corrcoef(y_test, ypred)\n",
    "    conf_mat       = confusion_matrix(y_test, ypred)\n",
    "    \n",
    "    misclassified     = np.where(y_test != ypred)[0]\n",
    " \n",
    "    name_file = open(filename + \".txt\", 'w')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.write('******* Testing Phase '+ str(classifier_model) +' for ' + str(classes) + ' *******\\n')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.write(\"Accuracy: \"                    + \"%f\" % float(accuracy) + '\\n')\n",
    "    name_file.write(\"Mathews Correlation Coef: \"    + \"%f\" % float(MCC)      + '\\n')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.write('Classification Report\\n')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.write(classification_report(y_test, ypred, target_names = classes)+'\\n')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.close()\n",
    "        \n",
    "    return ypred, accuracy, MCC, conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes_types,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(9,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=16)\n",
    "    cb=plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    cb.ax.tick_params(labelsize=16)\n",
    "    tick_marks = np.arange(len(classes_types))\n",
    "    plt.xticks(tick_marks, classes_types, rotation=45)\n",
    "    plt.yticks(tick_marks, classes_types)\n",
    "    plt.tick_params(axis='x', labelsize=16)\n",
    "    plt.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if (cm[i, j] < 0.01) or (cm[i,j] >= 0.75)  else \"black\",fontsize=16)\n",
    "\n",
    "    \n",
    "    plt.ylabel('True label',fontsize = 16)\n",
    "    plt.xlabel('Predicted label', fontsize = 16)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(conf_mat, classes_types, classifier_model, plot_title, X_test, y_test, nClasses,cmap=plt.cm.Reds):\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    \n",
    "    plot_confusion_matrix(conf_mat, classes_types, normalize=True, title='Confusion matrix for ' + str(classifier_model) )\n",
    "    plt.savefig(plot_title +'_CM.pdf')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analysis_rf(X_train, y_train, types,save_model=False):\n",
    "    n_estimators      = np.arange(50,1000,100)\n",
    "    max_features      = ['auto', 'sqrt', 'log2']\n",
    "    min_samples_split = np.arange(1,20,1)\n",
    "    #max_depth         = np.arange(1,10,2)\n",
    "    param_grid        = dict(n_estimators=n_estimators, max_features=max_features, \\\n",
    "                              min_samples_split=min_samples_split)#,max_depth=max_depth\n",
    "\n",
    "        \n",
    "    opt_parameters_rf = gridsearch(X_train,y_train,RandomForestClassifier(), param_grid, n_iter = 2, cv = 5, filename= results_dir + types+'_RF_hyparameters.txt')\n",
    "    fit_model = model_save(RandomForestClassifier(**opt_parameters_rf), X_train=X_train, y_train=y_train, \\\n",
    "                           filename_model= results_dir + types+'_RF_model.sav', save_model=save_model)\n",
    "    return opt_parameters_rf, fit_model\n",
    "\n",
    "def final_prediction(fitModel,X_train, y_train, X_test, y_test, classes, types, nClasses,load_model=False):\n",
    "\n",
    "    ypred, accuracy, MCC, conf_mat = model_fit(fitModel,filename_model= results_dir + types +'_RF_model.sav', X_train=X_train, y_train=y_train, X_test = X_test, y_test=y_test,\\\n",
    "                                                 classifier_model='Random Forest Classifier',classes=classes, filename =results_dir + types+'_RF',load_model=load_model)\n",
    "\n",
    "\n",
    "\n",
    "    plotting = plot(conf_mat, classes_types=classes, classifier_model='Random Forest Classifier',\\\n",
    "                                  plot_title= plots_dir + types + '_RF', X_test=X_test, y_test=y_test, nClasses=nClasses,cmap=plt.cm.Reds)\n",
    "\n",
    "    return ypred, accuracy, MCC, conf_mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analysis_XGB(X_train, y_train, types,save_model=False):\n",
    "    eta       = [0.01]\n",
    "    objective = ['multi:softmax']\n",
    "    max_depth = np.arange(1,12,2)\n",
    "    subsample  = [0.5]\n",
    "    param_grid        = dict(eta=eta,objective=objective,max_depth=max_depth,subsample=subsample)\n",
    "\n",
    "        \n",
    "    opt_parameters_XGB = gridsearch(X_train,y_train,XGBClassifier(), param_grid, n_iter = 5, cv = 5, filename= results_dir + types+ '_XGB_hyparameters.txt')\n",
    "    fit_model = model_save(XGBClassifier(**opt_parameters_XGB), X_train=X_train, y_train=y_train, \\\n",
    "                           filename_model= results_dir + types + '_XGB_model.sav', save_model=save_model)\n",
    "    return opt_parameters_XGB, fit_model\n",
    "\n",
    "def final_prediction_XGB(fitModel,X_train, y_train, X_test, y_test, classes, types,nClasses,load_model=False):\n",
    "    ypred, accuracy, MCC, conf_mat  = model_fit(fitModel,filename_model= results_dir + types +'_XGB_model.sav', X_train=X_train, y_train=y_train, X_test = X_test, y_test=y_test,\\\n",
    "                                                 classifier_model='XGBoost Classifier',classes=classes, filename =results_dir + types +'_XGB', load_model=load_model)\n",
    "\n",
    "\n",
    "    plotting = plot(conf_mat, classes_types=classes, classifier_model='XGBoost Classifier',\\\n",
    "                                  plot_title= plots_dir + types +'_XGB', X_test=X_test, y_test=y_test, nClasses=nClasses,cmap=plt.cm.Blues)\n",
    "    return ypred, accuracy, MCC, conf_mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training(n_splits,data_preparation=True,augmentation=True,multi_class=True):\n",
    "    if (multi_class == True):\n",
    "        data = features\n",
    "    else:\n",
    "        # For binary Classification\n",
    "        data = pd.concat([features[features[\"True_class_labels\"]==true_class_1],features[features[\"True_class_labels\"]==true_class_2]],axis=0)\n",
    "    print('The data consists of {} samples'.format(data.shape))\n",
    "    \n",
    "    X   = data.iloc[:,0:nFeatures]\n",
    "    y   = data.True_class_labels\n",
    "    \n",
    "    # For Testing Code\n",
    "#     X   = shuffle(X).iloc[0:2000,0:nFeatures]\n",
    "#     y   = y.iloc[X.index]\n",
    "\n",
    "    skf       = StratifiedKFold(n_splits=n_splits, shuffle=True) \n",
    "    split_num = 1\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "        if data_preparation:\n",
    "            X_train_index, X_test_index = X.index[train_index], X.index[test_index]\n",
    "            y_train_index, y_test_index = y.index[train_index], y.index[test_index]\n",
    "            training = shuffle(data.iloc[X_train_index])\n",
    "            testing  = shuffle(data.iloc[X_test_index])\n",
    "            \n",
    "            X_train_normalisation, y_train_np, filename_train, X_test_normalisation,\\\n",
    "            y_test_np, filename_test = normalisation(x_train=training,x_test=testing) \n",
    "            \n",
    "            if augmentation:\n",
    "                print(\"Before OverSampling, counts of label '1': {}\".format((y_train_np[y_train_np==1]).shape))\n",
    "                print(\"Before OverSampling, counts of label '2': {}\".format((y_train_np[y_train_np==2]).shape))\n",
    "                print(\"Before OverSampling, counts of label '3': {}\".format((y_train_np[y_train_np==3]).shape))\n",
    "                print(\"Before OverSampling, counts of label '4': {}\".format((y_train_np[y_train_np==4]).shape))\n",
    "                print(\"Before OverSampling, counts of label '5': {}\".format((y_train_np[y_train_np==5]).shape))\n",
    "                print(\"Before OverSampling, counts of label '6': {}\".format((y_train_np[y_train_np==6]).shape))\n",
    "                print(\"Before OverSampling, counts of label '7': {}\".format((y_train_np[y_train_np==7]).shape))\n",
    "                print(\"Before OverSampling, counts of label '8': {}\".format((y_train_np[y_train_np==8]).shape))\n",
    "                print(\"Before OverSampling, counts of label '9': {}\".format((y_train_np[y_train_np==9]).shape))\n",
    "                print(\"Before OverSampling, counts of label '10': {}\".format((y_train_np[y_train_np==10]).shape))\n",
    "                print(\"Before OverSampling, counts of label '12': {}\".format((y_train_np[y_train_np==12]).shape))\n",
    "                \n",
    "\n",
    "                # sm = SMOTE(random_state=2, ratio = 1.0,kind='svm')\n",
    "                sm = SMOTE(ratio = 'all') # Using Kind: Regular\n",
    "                X_train_aug, y_train_aug = sm.fit_sample(X_train_normalisation, y_train_np.ravel())\n",
    "                data_1 = pd.DataFrame(X_train_aug)\n",
    "                data_1['True_class_labels'] = y_train_aug\n",
    "                X_train_norm = data_1.iloc[:,0:nFeatures]\n",
    "                y_train_norm = data_1.iloc[:,nFeatures]\n",
    "\n",
    "                print('-'*70)\n",
    "                print(\"After OverSampling, counts of label '1': {}\".format(y_train_norm.loc[y_train_norm==1].shape))\n",
    "                print(\"After OverSampling, counts of label '2': {}\".format(y_train_norm.loc[y_train_norm==2].shape))\n",
    "                print(\"After OverSampling, counts of label '3': {}\".format(y_train_norm.loc[y_train_norm==3].shape))\n",
    "                print(\"After OverSampling, counts of label '4': {}\".format(y_train_norm.loc[y_train_norm==4].shape))\n",
    "                print(\"After OverSampling, counts of label '5': {}\".format(y_train_norm.loc[y_train_norm==5].shape))\n",
    "                print(\"After OverSampling, counts of label '6': {}\".format(y_train_norm.loc[y_train_norm==6].shape))\n",
    "                print(\"After OverSampling, counts of label '7': {}\".format(y_train_norm.loc[y_train_norm==7].shape))\n",
    "                print(\"After OverSampling, counts of label '8': {}\".format(y_train_norm.loc[y_train_norm==8].shape))\n",
    "                print(\"After OverSampling, counts of label '9': {}\".format(y_train_norm.loc[y_train_norm==9].shape))\n",
    "                print(\"After OverSampling, counts of label '10': {}\".format(y_train_norm.loc[y_train_norm==10].shape))\n",
    "                print(\"After OverSampling, counts of label '12': {}\".format(y_train_norm.loc[y_train_norm==12].shape))\n",
    "\n",
    "                X_train = X_train_norm   \n",
    "                y_train = y_train_norm\n",
    "                y_test  = y_test_np\n",
    "                X_test  = X_test_normalisation\n",
    "                               \n",
    "            else:\n",
    "                X_train = X_train_normalisation\n",
    "                y_test  = y_test_np\n",
    "                y_train = y_train_np\n",
    "                X_test  = X_test_normalisation\n",
    "            \n",
    "            \n",
    "            print(\"X_train shape: {}\".format(X_train.shape))\n",
    "            print(\"y_train shape: {}\".format(y_train.shape))\n",
    "            print(\"X_test shape: {}\".format(X_test.shape))\n",
    "            print(\"y_test shape: {}\".format(y_test.shape))\n",
    "            \n",
    "            types   = 'Type_all_Split_'+str(split_num)\n",
    "            \n",
    "            opt_rf, fit_model_rf = analysis_rf(X_train,y_train, types, save_model) # This part can be commented if you don't want to train the algorithm\n",
    "            print(opt_rf)\n",
    "\n",
    "            ypred_rf, accuracy_rf, MCC_rf, conf_mat_rf = final_prediction(fit_model_rf,X_train, y_train, X_test, y_test, classes_types, types, nClasses,load_model)\n",
    "\n",
    "            acc_rf.append(accuracy_rf)\n",
    "            mcc_rf.append(MCC_rf)\n",
    "\n",
    "            # XGBoost Classifier\n",
    "\n",
    "            opt_xgb, fit_model_xgb = analysis_XGB(X_train, y_train, types, save_model) # This part can be commented when no training\n",
    "            print(opt_xgb)\n",
    "\n",
    "            ypred_xgb, accuracy_xgb, MCC_xgb, conf_mat_xgb = final_prediction_XGB(fit_model_xgb, X_train, y_train, X_test, y_test, classes_types, types, nClasses, load_model)\n",
    "\n",
    "            acc_xgb.append(accuracy_xgb)\n",
    "            mcc_xgb.append(MCC_xgb)\n",
    "\n",
    "        print('Preprocessing for Split {} is finished'.format(split_num))  \n",
    "        split_num += 1\n",
    "        \n",
    "    print('Accuracy for RF is {}%'.format(np.mean(acc_rf)*100))\n",
    "    print('MCC for RF is {}'.format(np.mean(mcc_rf)))\n",
    "\n",
    "    print('Accuracy for XGB is {}%'.format(np.mean(acc_xgb)*100))\n",
    "    print('MCC for XGB is {}'.format(np.mean(mcc_xgb)))\n",
    "\n",
    "    metrics = open(\"./multi-class-results_SMOTE/metrics.txt\", 'w')\n",
    "    metrics.write('='*80+'\\n')\n",
    "    metrics.write('***Testing Phase Random Forest for ' + str(classes_types) + ' ***\\n')\n",
    "    metrics.write('='*80+'\\n')\n",
    "    metrics.write(\"Accuracy: ({} ± {}) %\".format(np.mean(acc_rf)*100,np.std(acc_rf)) + '\\n')\n",
    "    metrics.write(\"MCC: ({} ± {})\".format(np.mean(mcc_rf)*100,np.std(mcc_rf)) + '\\n')\n",
    "\n",
    "    metrics.write('='*80+'\\n')\n",
    "    metrics.write('***Testing Phase XGBoost for ' + str(classes_types) + ' ***\\n')\n",
    "    metrics.write('='*80+'\\n')\n",
    "    metrics.write(\"Accuracy: ({} ± {}) %\".format(np.mean(acc_xgb)*100,np.std(acc_xgb)) + '\\n')\n",
    "    metrics.write(\"MCC: ({} ± {})\".format(np.mean(mcc_xgb)*100,np.std(mcc_xgb)) + '\\n')\n",
    "    metrics.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Section Needs to be changed each time\n",
    "nFeatures = 7\n",
    "\n",
    "true_class_1=1;true_class_2=2;true_class_3=3;true_class_4=4;true_class_5=5;true_class_6=6;true_class_7=7;\\\n",
    "true_class_8=8;true_class_9=9;true_class_10=10;true_class_11=11;true_class_12=12;true_class_13=13\n",
    "\n",
    "plots_dir                 = './multi-class-results_SMOTE/plots/'\n",
    "results_dir               = './multi-class-results_SMOTE/results/'\n",
    "misclassify_dir           = r'./multi-class-results_SMOTE/results/Misclassification_'\n",
    "dotfile_dir               = './multi-class-results_SMOTE/Decision_tree_plots/'\n",
    "savedir_decision_boundary ='./multi-class-results_SMOTE/decision_boundary_plots/'\n",
    "feature_directory         ='./data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data consists of (23143, 9) samples\n"
     ]
    }
   ],
   "source": [
    "n_splits         = 5\n",
    "data_preparation = True\n",
    "multi_class      = True\n",
    "augmentation     = True\n",
    "save_model       = False\n",
    "load_model       = False\n",
    "feature_data     = 'features_alldata.csv'\n",
    "features         = pd.read_csv(feature_directory+feature_data)\n",
    "print('The data consists of {} samples'.format(features.shape))\n",
    "# This Section Needs to be changed each time\n",
    "classes_types = ['RRab', \"RRc\", \"RRd\", 'Blazhko', 'Ecl', 'EA', 'Rot', 'LPV','$\\delta$-Scuti', 'ACEP', 'Cep-II']\n",
    "nClasses      = 11\n",
    "acc_rf = [];mcc_rf = [];acc_xgb = [];mcc_xgb = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data consists of (23143, 9) samples\n",
      "Before OverSampling, counts of label '1': (3460,)\n",
      "Before OverSampling, counts of label '2': (3001,)\n",
      "Before OverSampling, counts of label '3': (401,)\n",
      "Before OverSampling, counts of label '4': (136,)\n",
      "Before OverSampling, counts of label '5': (3607,)\n",
      "Before OverSampling, counts of label '6': (3607,)\n",
      "Before OverSampling, counts of label '7': (2908,)\n",
      "Before OverSampling, counts of label '8': (1028,)\n",
      "Before OverSampling, counts of label '9': (117,)\n",
      "Before OverSampling, counts of label '10': (122,)\n",
      "Before OverSampling, counts of label '12': (122,)\n",
      "----------------------------------------------------------------------\n",
      "After OverSampling, counts of label '1': (3607,)\n",
      "After OverSampling, counts of label '2': (3607,)\n",
      "After OverSampling, counts of label '3': (3607,)\n",
      "After OverSampling, counts of label '4': (3607,)\n",
      "After OverSampling, counts of label '5': (3607,)\n",
      "After OverSampling, counts of label '6': (3607,)\n",
      "After OverSampling, counts of label '7': (3607,)\n",
      "After OverSampling, counts of label '8': (3607,)\n",
      "After OverSampling, counts of label '9': (3607,)\n",
      "After OverSampling, counts of label '10': (3607,)\n",
      "After OverSampling, counts of label '12': (3607,)\n",
      "X_train shape: (39677, 7)\n",
      "y_train shape: (39677,)\n",
      "X_test shape: (4634, 7)\n",
      "y_test shape: (4634,)\n",
      "{'n_estimators': 750, 'min_samples_split': 4, 'max_features': 'auto'}\n",
      "{'n_estimators': 750, 'min_samples_split': 4, 'max_features': 'auto'}\n",
      "Normalized confusion matrix\n",
      "[[ 0.85202312  0.00231214  0.00231214  0.07283237  0.01040462  0.02543353\n",
      "   0.02312139  0.          0.          0.01156069  0.        ]\n",
      " [ 0.00266312  0.74567244  0.09054594  0.          0.11451398  0.00399467\n",
      "   0.04260985  0.          0.          0.          0.        ]\n",
      " [ 0.01980198  0.40594059  0.40594059  0.          0.0990099   0.\n",
      "   0.05940594  0.          0.          0.00990099  0.        ]\n",
      " [ 0.45714286  0.          0.          0.54285714  0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.03658537  0.13303769  0.03325942  0.00332594  0.56208426  0.05654102\n",
      "   0.16075388  0.00110865  0.          0.01108647  0.00221729]\n",
      " [ 0.01995565  0.00221729  0.00443459  0.00443459  0.04323725  0.88026608\n",
      "   0.03104213  0.          0.          0.00776053  0.00665188]\n",
      " [ 0.04807692  0.07417582  0.00961538  0.00412088  0.13461538  0.04945055\n",
      "   0.61538462  0.02472527  0.          0.01098901  0.02884615]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.01550388  0.98449612  0.          0.          0.        ]\n",
      " [ 0.03333333  0.          0.          0.          0.          0.\n",
      "   0.03333333  0.          0.93333333  0.          0.        ]\n",
      " [ 0.12903226  0.          0.          0.          0.03225806  0.\n",
      "   0.06451613  0.          0.          0.61290323  0.16129032]\n",
      " [ 0.03225806  0.          0.          0.          0.03225806  0.03225806\n",
      "   0.12903226  0.03225806  0.          0.09677419  0.64516129]]\n",
      "{'objective': 'multi:softmax', 'subsample': 0.5, 'eta': 0.01, 'max_depth': 9}\n",
      "{'objective': 'multi:softmax', 'subsample': 0.5, 'eta': 0.01, 'max_depth': 9}\n",
      "Normalized confusion matrix\n",
      "[[ 0.85086705  0.00115607  0.00462428  0.08786127  0.0150289   0.01618497\n",
      "   0.01387283  0.          0.          0.00924855  0.00115607]\n",
      " [ 0.          0.71238349  0.12782956  0.          0.11051931  0.00399467\n",
      "   0.04527297  0.          0.          0.          0.        ]\n",
      " [ 0.01980198  0.35643564  0.48514851  0.          0.08910891  0.\n",
      "   0.03960396  0.          0.          0.00990099  0.        ]\n",
      " [ 0.31428571  0.          0.          0.68571429  0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.03215078  0.13636364  0.0421286   0.00110865  0.54323725  0.06208426\n",
      "   0.16740576  0.          0.          0.01219512  0.00332594]\n",
      " [ 0.01662971  0.00332594  0.00332594  0.00665188  0.05099778  0.87915743\n",
      "   0.02882483  0.          0.          0.00776053  0.00332594]\n",
      " [ 0.04532967  0.07417582  0.0206044   0.00412088  0.13873626  0.03434066\n",
      "   0.60989011  0.0260989   0.          0.01373626  0.03296703]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.01937984  0.97674419  0.          0.          0.00387597]\n",
      " [ 0.          0.03333333  0.          0.          0.          0.\n",
      "   0.03333333  0.          0.93333333  0.          0.        ]\n",
      " [ 0.09677419  0.          0.          0.          0.03225806  0.\n",
      "   0.09677419  0.          0.          0.67741935  0.09677419]\n",
      " [ 0.03225806  0.          0.          0.          0.          0.03225806\n",
      "   0.16129032  0.03225806  0.          0.09677419  0.64516129]]\n",
      "Preprocessing for Split 1 is finished\n",
      "Before OverSampling, counts of label '1': (3460,)\n",
      "Before OverSampling, counts of label '2': (3001,)\n",
      "Before OverSampling, counts of label '3': (401,)\n",
      "Before OverSampling, counts of label '4': (137,)\n",
      "Before OverSampling, counts of label '5': (3607,)\n",
      "Before OverSampling, counts of label '6': (3607,)\n",
      "Before OverSampling, counts of label '7': (2909,)\n",
      "Before OverSampling, counts of label '8': (1029,)\n",
      "Before OverSampling, counts of label '9': (117,)\n",
      "Before OverSampling, counts of label '10': (122,)\n",
      "Before OverSampling, counts of label '12': (122,)\n",
      "----------------------------------------------------------------------\n",
      "After OverSampling, counts of label '1': (3607,)\n",
      "After OverSampling, counts of label '2': (3607,)\n",
      "After OverSampling, counts of label '3': (3607,)\n",
      "After OverSampling, counts of label '4': (3607,)\n",
      "After OverSampling, counts of label '5': (3607,)\n",
      "After OverSampling, counts of label '6': (3607,)\n",
      "After OverSampling, counts of label '7': (3607,)\n",
      "After OverSampling, counts of label '8': (3607,)\n",
      "After OverSampling, counts of label '9': (3607,)\n",
      "After OverSampling, counts of label '10': (3607,)\n",
      "After OverSampling, counts of label '12': (3607,)\n",
      "X_train shape: (39677, 7)\n",
      "y_train shape: (39677,)\n",
      "X_test shape: (4631, 7)\n",
      "y_test shape: (4631,)\n",
      "{'n_estimators': 750, 'min_samples_split': 4, 'max_features': 'auto'}\n",
      "{'n_estimators': 750, 'min_samples_split': 4, 'max_features': 'auto'}\n",
      "Normalized confusion matrix\n",
      "[[ 0.86242775  0.00115607  0.00115607  0.05895954  0.00693642  0.02080925\n",
      "   0.03236994  0.          0.          0.01618497  0.        ]\n",
      " [ 0.00399467  0.69773635  0.11451398  0.          0.13182423  0.00266312\n",
      "   0.04660453  0.          0.00266312  0.          0.        ]\n",
      " [ 0.03960396  0.23762376  0.58415842  0.00990099  0.08910891  0.\n",
      "   0.02970297  0.          0.          0.00990099  0.        ]\n",
      " [ 0.52941176  0.          0.02941176  0.38235294  0.          0.05882353\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.02660754  0.13303769  0.02771619  0.00221729  0.57317073  0.06208426\n",
      "   0.16407982  0.          0.00110865  0.00776053  0.00221729]\n",
      " [ 0.0232816   0.00665188  0.00332594  0.          0.03769401  0.87694013\n",
      "   0.04767184  0.          0.          0.          0.00443459]\n",
      " [ 0.03301238  0.07015131  0.02063274  0.00137552  0.14030261  0.03163686\n",
      "   0.62310867  0.01925722  0.00275103  0.01788171  0.03988996]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.0155642   0.9844358   0.          0.          0.        ]\n",
      " [ 0.03333333  0.1         0.          0.          0.03333333  0.\n",
      "   0.03333333  0.          0.8         0.          0.        ]\n",
      " [ 0.12903226  0.          0.          0.          0.          0.16129032\n",
      "   0.          0.          0.          0.67741935  0.03225806]\n",
      " [ 0.03225806  0.03225806  0.          0.          0.          0.06451613\n",
      "   0.16129032  0.          0.          0.19354839  0.51612903]]\n",
      "{'objective': 'multi:softmax', 'subsample': 0.5, 'eta': 0.01, 'max_depth': 9}\n",
      "{'objective': 'multi:softmax', 'subsample': 0.5, 'eta': 0.01, 'max_depth': 9}\n",
      "Normalized confusion matrix\n",
      "[[ 0.83815029  0.00115607  0.00231214  0.0867052   0.01156069  0.01734104\n",
      "   0.02427746  0.          0.          0.01849711  0.        ]\n",
      " [ 0.          0.69241012  0.13848202  0.          0.11850866  0.00399467\n",
      "   0.04260985  0.          0.00399467  0.          0.        ]\n",
      " [ 0.03960396  0.23762376  0.6039604   0.00990099  0.06930693  0.\n",
      "   0.02970297  0.          0.          0.00990099  0.        ]\n",
      " [ 0.38235294  0.          0.02941176  0.52941176  0.02941176  0.02941176\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.02771619  0.12084257  0.04878049  0.00221729  0.57427938  0.0654102\n",
      "   0.14855876  0.          0.00221729  0.00886918  0.00110865]\n",
      " [ 0.01552106  0.00443459  0.00221729  0.00110865  0.04767184  0.87915743\n",
      "   0.04323725  0.          0.          0.00221729  0.00443459]\n",
      " [ 0.03163686  0.06740028  0.02200825  0.00412655  0.14855571  0.02751032\n",
      "   0.6176066   0.01788171  0.00275103  0.02063274  0.03988996]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.00389105  0.99610895  0.          0.          0.        ]\n",
      " [ 0.03333333  0.06666667  0.          0.          0.03333333  0.          0.\n",
      "   0.          0.86666667  0.          0.        ]\n",
      " [ 0.12903226  0.          0.          0.          0.          0.16129032\n",
      "   0.          0.          0.          0.67741935  0.03225806]\n",
      " [ 0.          0.03225806  0.          0.          0.          0.03225806\n",
      "   0.19354839  0.          0.          0.22580645  0.51612903]]\n",
      "Preprocessing for Split 2 is finished\n",
      "Before OverSampling, counts of label '1': (3460,)\n",
      "Before OverSampling, counts of label '2': (3002,)\n",
      "Before OverSampling, counts of label '3': (402,)\n",
      "Before OverSampling, counts of label '4': (137,)\n",
      "Before OverSampling, counts of label '5': (3607,)\n",
      "Before OverSampling, counts of label '6': (3607,)\n",
      "Before OverSampling, counts of label '7': (2909,)\n",
      "Before OverSampling, counts of label '8': (1029,)\n",
      "Before OverSampling, counts of label '9': (118,)\n",
      "Before OverSampling, counts of label '10': (122,)\n",
      "Before OverSampling, counts of label '12': (122,)\n",
      "----------------------------------------------------------------------\n",
      "After OverSampling, counts of label '1': (3607,)\n",
      "After OverSampling, counts of label '2': (3607,)\n",
      "After OverSampling, counts of label '3': (3607,)\n",
      "After OverSampling, counts of label '4': (3607,)\n",
      "After OverSampling, counts of label '5': (3607,)\n",
      "After OverSampling, counts of label '6': (3607,)\n",
      "After OverSampling, counts of label '7': (3607,)\n",
      "After OverSampling, counts of label '8': (3607,)\n",
      "After OverSampling, counts of label '9': (3607,)\n",
      "After OverSampling, counts of label '10': (3607,)\n",
      "After OverSampling, counts of label '12': (3607,)\n",
      "X_train shape: (39677, 7)\n",
      "y_train shape: (39677,)\n",
      "X_test shape: (4628, 7)\n",
      "y_test shape: (4628,)\n",
      "{'n_estimators': 750, 'min_samples_split': 4, 'max_features': 'auto'}\n",
      "{'n_estimators': 750, 'min_samples_split': 4, 'max_features': 'auto'}\n",
      "Normalized confusion matrix\n",
      "[[ 0.86127168  0.          0.00231214  0.06127168  0.01271676  0.02312139\n",
      "   0.02196532  0.          0.          0.0150289   0.00231214]\n",
      " [ 0.008       0.74266667  0.09466667  0.          0.11066667  0.00133333\n",
      "   0.04        0.          0.00266667  0.          0.        ]\n",
      " [ 0.          0.39        0.44        0.          0.13        0.          0.03\n",
      "   0.          0.          0.01        0.        ]\n",
      " [ 0.58823529  0.          0.          0.41176471  0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.03658537  0.11640798  0.04656319  0.00221729  0.5421286   0.06430155\n",
      "   0.17960089  0.          0.          0.00776053  0.00443459]\n",
      " [ 0.03104213  0.00554324  0.          0.00110865  0.0443459   0.86585366\n",
      "   0.03991131  0.          0.          0.00776053  0.00443459]\n",
      " [ 0.0605227   0.0784044   0.02063274  0.          0.15268226  0.03713893\n",
      "   0.58596974  0.02200825  0.00137552  0.01100413  0.03026135]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.0155642   0.98054475  0.          0.          0.00389105]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.06451613  0.          0.          0.          0.          0.\n",
      "   0.03225806  0.          0.          0.83870968  0.06451613]\n",
      " [ 0.          0.          0.          0.          0.          0.09677419\n",
      "   0.16129032  0.          0.          0.16129032  0.58064516]]\n",
      "{'objective': 'multi:softmax', 'subsample': 0.5, 'eta': 0.01, 'max_depth': 9}\n",
      "{'objective': 'multi:softmax', 'subsample': 0.5, 'eta': 0.01, 'max_depth': 9}\n",
      "Normalized confusion matrix\n",
      "[[ 0.83352601  0.00115607  0.00462428  0.09132948  0.00809249  0.01849711\n",
      "   0.02427746  0.          0.          0.01734104  0.00115607]\n",
      " [ 0.00266667  0.71066667  0.124       0.00133333  0.10266667  0.00266667\n",
      "   0.052       0.          0.004       0.          0.        ]\n",
      " [ 0.          0.31        0.53        0.          0.12        0.          0.03\n",
      "   0.          0.          0.01        0.        ]\n",
      " [ 0.44117647  0.          0.          0.55882353  0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.03104213  0.11086475  0.05654102  0.00443459  0.55210643  0.06208426\n",
      "   0.17184035  0.          0.          0.00997783  0.00110865]\n",
      " [ 0.02217295  0.00776053  0.00332594  0.00110865  0.03658537  0.88137472\n",
      "   0.03547672  0.          0.          0.00554324  0.00665188]\n",
      " [ 0.06327373  0.07565337  0.02475928  0.          0.13204952  0.02888583\n",
      "   0.60797799  0.02063274  0.00137552  0.01237964  0.03301238]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.01167315  0.9844358   0.          0.          0.00389105]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.93548387  0.06451613]\n",
      " [ 0.          0.          0.          0.          0.          0.03225806\n",
      "   0.16129032  0.          0.          0.12903226  0.67741935]]\n",
      "Preprocessing for Split 3 is finished\n",
      "Before OverSampling, counts of label '1': (3460,)\n",
      "Before OverSampling, counts of label '2': (3002,)\n",
      "Before OverSampling, counts of label '3': (402,)\n",
      "Before OverSampling, counts of label '4': (137,)\n",
      "Before OverSampling, counts of label '5': (3607,)\n",
      "Before OverSampling, counts of label '6': (3607,)\n",
      "Before OverSampling, counts of label '7': (2909,)\n",
      "Before OverSampling, counts of label '8': (1029,)\n",
      "Before OverSampling, counts of label '9': (118,)\n",
      "Before OverSampling, counts of label '10': (123,)\n",
      "Before OverSampling, counts of label '12': (123,)\n",
      "----------------------------------------------------------------------\n",
      "After OverSampling, counts of label '1': (3607,)\n",
      "After OverSampling, counts of label '2': (3607,)\n",
      "After OverSampling, counts of label '3': (3607,)\n",
      "After OverSampling, counts of label '4': (3607,)\n",
      "After OverSampling, counts of label '5': (3607,)\n",
      "After OverSampling, counts of label '6': (3607,)\n",
      "After OverSampling, counts of label '7': (3607,)\n",
      "After OverSampling, counts of label '8': (3607,)\n",
      "After OverSampling, counts of label '9': (3607,)\n",
      "After OverSampling, counts of label '10': (3607,)\n",
      "After OverSampling, counts of label '12': (3607,)\n",
      "X_train shape: (39677, 7)\n",
      "y_train shape: (39677,)\n",
      "X_test shape: (4626, 7)\n",
      "y_test shape: (4626,)\n",
      "{'n_estimators': 750, 'min_samples_split': 4, 'max_features': 'auto'}\n",
      "{'n_estimators': 750, 'min_samples_split': 4, 'max_features': 'auto'}\n",
      "Normalized confusion matrix\n",
      "[[ 0.88439306  0.00231214  0.00578035  0.04855491  0.00693642  0.01965318\n",
      "   0.02543353  0.          0.          0.00693642  0.        ]\n",
      " [ 0.00266667  0.72933333  0.116       0.          0.1         0.00133333\n",
      "   0.048       0.          0.00133333  0.          0.00133333]\n",
      " [ 0.05        0.33        0.49        0.01        0.1         0.          0.02\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.67647059  0.          0.          0.29411765  0.          0.\n",
      "   0.02941176  0.          0.          0.          0.        ]\n",
      " [ 0.02771619  0.13192905  0.04878049  0.00110865  0.5654102   0.05986696\n",
      "   0.15077605  0.          0.00443459  0.00554324  0.00443459]\n",
      " [ 0.02217295  0.00665188  0.00110865  0.          0.0443459   0.86474501\n",
      "   0.04878049  0.          0.00110865  0.00443459  0.00665188]\n",
      " [ 0.04126547  0.08803301  0.03713893  0.          0.14167813  0.03988996\n",
      "   0.57771664  0.01513067  0.00687758  0.00962861  0.04264099]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.0233463   0.9688716   0.          0.          0.0077821 ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.1         0.          0.          0.          0.          0.1\n",
      "   0.03333333  0.          0.          0.76666667  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.1\n",
      "   0.          0.          0.06666667  0.83333333]]\n",
      "{'objective': 'multi:softmax', 'subsample': 0.5, 'eta': 0.01, 'max_depth': 9}\n",
      "{'objective': 'multi:softmax', 'subsample': 0.5, 'eta': 0.01, 'max_depth': 9}\n",
      "Normalized confusion matrix\n",
      "[[ 0.86011561  0.00462428  0.01040462  0.0716763   0.00924855  0.01156069\n",
      "   0.0265896   0.          0.          0.00578035  0.        ]\n",
      " [ 0.00266667  0.73066667  0.132       0.          0.08133333  0.004\n",
      "   0.04666667  0.          0.00133333  0.          0.00133333]\n",
      " [ 0.04        0.29        0.53        0.02        0.09        0.01        0.02\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.61764706  0.          0.          0.35294118  0.          0.02941176\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.02882483  0.12084257  0.06097561  0.          0.56208426  0.06097561\n",
      "   0.154102    0.          0.00221729  0.00665188  0.00332594]\n",
      " [ 0.02660754  0.00665188  0.00221729  0.00110865  0.04767184  0.86363636\n",
      "   0.0421286   0.          0.00110865  0.00221729  0.00665188]\n",
      " [ 0.03301238  0.07565337  0.03988996  0.00275103  0.1389271   0.04264099\n",
      "   0.59697387  0.01788171  0.00412655  0.00962861  0.03851444]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.0311284   0.95719844  0.          0.          0.01167315]\n",
      " [ 0.          0.03448276  0.          0.          0.          0.          0.\n",
      "   0.          0.96551724  0.          0.        ]\n",
      " [ 0.03333333  0.          0.          0.          0.          0.06666667\n",
      "   0.          0.          0.          0.83333333  0.06666667]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.16666667  0.          0.          0.06666667  0.76666667]]\n",
      "Preprocessing for Split 4 is finished\n",
      "Before OverSampling, counts of label '1': (3460,)\n",
      "Before OverSampling, counts of label '2': (3002,)\n",
      "Before OverSampling, counts of label '3': (402,)\n",
      "Before OverSampling, counts of label '4': (137,)\n",
      "Before OverSampling, counts of label '5': (3608,)\n",
      "Before OverSampling, counts of label '6': (3608,)\n",
      "Before OverSampling, counts of label '7': (2909,)\n",
      "Before OverSampling, counts of label '8': (1029,)\n",
      "Before OverSampling, counts of label '9': (118,)\n",
      "Before OverSampling, counts of label '10': (123,)\n",
      "Before OverSampling, counts of label '12': (123,)\n",
      "----------------------------------------------------------------------\n",
      "After OverSampling, counts of label '1': (3608,)\n",
      "After OverSampling, counts of label '2': (3608,)\n",
      "After OverSampling, counts of label '3': (3608,)\n",
      "After OverSampling, counts of label '4': (3608,)\n",
      "After OverSampling, counts of label '5': (3608,)\n",
      "After OverSampling, counts of label '6': (3608,)\n",
      "After OverSampling, counts of label '7': (3608,)\n",
      "After OverSampling, counts of label '8': (3608,)\n",
      "After OverSampling, counts of label '9': (3608,)\n",
      "After OverSampling, counts of label '10': (3608,)\n",
      "After OverSampling, counts of label '12': (3608,)\n",
      "X_train shape: (39688, 7)\n",
      "y_train shape: (39688,)\n",
      "X_test shape: (4624, 7)\n",
      "y_test shape: (4624,)\n",
      "{'n_estimators': 750, 'min_samples_split': 4, 'max_features': 'auto'}\n",
      "{'n_estimators': 750, 'min_samples_split': 4, 'max_features': 'auto'}\n",
      "Normalized confusion matrix\n",
      "[[ 0.86820809  0.00231214  0.00231214  0.05780347  0.0150289   0.02774566\n",
      "   0.02080925  0.          0.00115607  0.00462428  0.        ]\n",
      " [ 0.00266667  0.70933333  0.09733333  0.          0.13333333  0.\n",
      "   0.05466667  0.          0.00133333  0.00133333  0.        ]\n",
      " [ 0.06        0.25        0.44        0.02        0.18        0.          0.05\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.5         0.          0.          0.5         0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.02219756  0.12097669  0.03329634  0.00221976  0.57824639  0.06437292\n",
      "   0.16759156  0.          0.00332963  0.00776915  0.        ]\n",
      " [ 0.0199778   0.00221976  0.00332963  0.00110988  0.02663707  0.8845727\n",
      "   0.04772475  0.          0.          0.00332963  0.01109878]\n",
      " [ 0.04951857  0.09215956  0.01513067  0.00137552  0.15405777  0.05089409\n",
      "   0.58321871  0.00825309  0.00137552  0.01237964  0.03163686]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.0077821   0.9922179   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.13333333  0.          0.          0.          0.          0.06666667\n",
      "   0.          0.          0.          0.73333333  0.06666667]\n",
      " [ 0.          0.          0.03333333  0.          0.03333333  0.06666667\n",
      "   0.26666667  0.          0.          0.1         0.5       ]]\n",
      "{'objective': 'multi:softmax', 'subsample': 0.5, 'eta': 0.01, 'max_depth': 9}\n",
      "{'objective': 'multi:softmax', 'subsample': 0.5, 'eta': 0.01, 'max_depth': 9}\n",
      "Normalized confusion matrix\n",
      "[[ 0.85317919  0.00115607  0.00346821  0.07514451  0.01965318  0.01734104\n",
      "   0.02196532  0.          0.00115607  0.00693642  0.        ]\n",
      " [ 0.          0.724       0.112       0.          0.09866667  0.00133333\n",
      "   0.06133333  0.          0.00133333  0.00133333  0.        ]\n",
      " [ 0.05        0.19        0.57        0.02        0.13        0.          0.04\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.47058824  0.          0.          0.52941176  0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.02774695  0.09988901  0.04661487  0.00221976  0.59489456  0.05216426\n",
      "   0.16759156  0.          0.00110988  0.00665927  0.00110988]\n",
      " [ 0.01331853  0.00110988  0.00332963  0.00332963  0.04328524  0.8745838\n",
      "   0.04217536  0.          0.          0.00665927  0.01220866]\n",
      " [ 0.05089409  0.08115543  0.02338377  0.          0.15543329  0.04814305\n",
      "   0.58184319  0.00825309  0.00275103  0.01375516  0.0343879 ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.0077821   0.9922179   0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.06666667  0.          0.          0.          0.          0.06666667\n",
      "   0.03333333  0.          0.          0.73333333  0.1       ]\n",
      " [ 0.          0.          0.03333333  0.          0.03333333  0.1\n",
      "   0.23333333  0.          0.          0.06666667  0.53333333]]\n",
      "Preprocessing for Split 5 is finished\n",
      "Accuracy for RF is 73.6247599247%\n",
      "MCC for RF is 0.687053381729\n",
      "Accuracy for XGB is 73.5083662288%\n",
      "MCC for XGB is 0.68694232446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11af34290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11af61150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a55a5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a55ee90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c8b7610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15787ba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15787bb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ac24fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11dc96f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x156644c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
