{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import pickle\n",
    "#plt.switch_backend('agg')\n",
    "% matplotlib inline\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "figSize  = (12, 8)\n",
    "fontSize = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import itertools\n",
    "from scipy import interp\n",
    "from itertools import cycle, islice\n",
    "#from keras.utils import np_utils\n",
    "\n",
    "# Some preprocessing utilities\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.manifold.t_sne import TSNE\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# The different classifiers\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_data = 'features_alldata.csv'\n",
    "features     = pd.read_csv(feature_directory+feature_data)\n",
    "print(features.shape)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Features dataset for the First Layer\n",
    "\n",
    "It consists of Eclipsing Binary,  Rotational (Type 7) , and Pulsating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets shape: (23143, 7)\n",
      "FileName (Datasets) shape: (23143,)\n",
      "True label shape: (23143,)\n"
     ]
    }
   ],
   "source": [
    "# This Line of code needs to be changed each time (X and filenames and classes)\n",
    "# Building the target \n",
    "#The part below needs to be changed to know which class to classify. \n",
    "#Update type 1, type 2 and other class.\n",
    "X         = np.concatenate(( features_1[:,:], features_2[:,:], features_3[:,:],features_4[:,:],\\\n",
    "                            features_5[0:4509,:], features_6[:,:], features_7[:,:], features_8[:,:], features_9[:,:],\\\n",
    "                           features_10[:,:], features_12[:,:]), axis=0)#features_13[:,:]\n",
    "filenames = np.concatenate(( filename_1,filename_2,filename_3,filename_4, filename_5[0:4509], filename_6,filename_7,\n",
    "                           filename_8,filename_9,filename_10,filename_12), axis=0)#,filename_13\n",
    "classes   = np.concatenate((class_1,class_2, class_3,class_4, class_5, class_6, class_7,class_8,class_9,class_10,\\\n",
    "                           class_12), axis=0)#,class_13\n",
    "\n",
    "print(\"Datasets shape: %s\" % str(X.shape))\n",
    "print(\"FileName (Datasets) shape: %s\" % str(filenames.shape))\n",
    "print(\"True label shape: %s\" % str(classes.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Sigma</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Period</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Mean Variance</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>True_class_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.723422</td>\n",
       "      <td>14.79140</td>\n",
       "      <td>0.235842</td>\n",
       "      <td>-0.509129</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.395027</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>3019021001365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.060895</td>\n",
       "      <td>19.33822</td>\n",
       "      <td>0.437060</td>\n",
       "      <td>-0.642995</td>\n",
       "      <td>0.467078</td>\n",
       "      <td>0.798282</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>3019094000701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.949758</td>\n",
       "      <td>17.38848</td>\n",
       "      <td>0.241550</td>\n",
       "      <td>9.202229</td>\n",
       "      <td>0.617775</td>\n",
       "      <td>0.373168</td>\n",
       "      <td>0.013891</td>\n",
       "      <td>3019100001287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.454850</td>\n",
       "      <td>17.66133</td>\n",
       "      <td>0.265296</td>\n",
       "      <td>0.798117</td>\n",
       "      <td>0.606604</td>\n",
       "      <td>0.480441</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>3019117005772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737083</td>\n",
       "      <td>17.28145</td>\n",
       "      <td>0.247050</td>\n",
       "      <td>0.272187</td>\n",
       "      <td>0.467006</td>\n",
       "      <td>0.482049</td>\n",
       "      <td>0.014296</td>\n",
       "      <td>3019118005110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Skew      Mean     Sigma  Kurtosis    Period  Amplitude  Mean Variance  \\\n",
       "0 -0.723422  14.79140  0.235842 -0.509129  0.488195   0.395027       0.015945   \n",
       "1 -0.060895  19.33822  0.437060 -0.642995  0.467078   0.798282       0.022601   \n",
       "2 -1.949758  17.38848  0.241550  9.202229  0.617775   0.373168       0.013891   \n",
       "3 -0.454850  17.66133  0.265296  0.798117  0.606604   0.480441       0.015021   \n",
       "4 -0.737083  17.28145  0.247050  0.272187  0.467006   0.482049       0.014296   \n",
       "\n",
       "       File_Name  True_class_labels  \n",
       "0  3019021001365                  1  \n",
       "1  3019094000701                  1  \n",
       "2  3019100001287                  1  \n",
       "3  3019117005772                  1  \n",
       "4  3019118005110                  1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data                       = pd.DataFrame(X)\n",
    "data                       = data.drop(labels=4, axis=1)\n",
    "data['File_Name']          = filenames\n",
    "data['True_class_labels']  = classes\n",
    "\n",
    "lC_dir = '../SSS_Per_Var_Cat/'\n",
    "period_data = pd.read_csv('../Ascii_SSS_Per_Table.txt',delim_whitespace=True,names = [\"SSS_ID\", \"File_Name\", \"RA\", \"Dec\", \"Period\", \"V_CSS\", \"Npts\", \"V_amp\", \"Type\", \"Prior_ID\", \"No_Name1\", 'No_Name2'])\n",
    "\n",
    "periods = period_data[['File_Name', 'Period']]\n",
    "data['File_Name']=data['File_Name'].astype(int)\n",
    "data = data.join(periods.set_index('File_Name'), on='File_Name')\n",
    "data = data[[0,1,2,3, 'Period',5,6, 'File_Name', 'True_class_labels']]\n",
    "data = data.rename(columns = {0:'Skew',1:'Mean',2:'Sigma', 3:'Kurtosis', \\\n",
    "                            4:'Period LS', 5:'Amplitude', 6:'Mean Variance'})\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling each class of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RRab        = data[data['True_class_labels'] == 1]\n",
    "RRc         = data[data['True_class_labels'] == 2]\n",
    "RRd         = data[data['True_class_labels'] == 3]\n",
    "blazhko     = data[data['True_class_labels'] == 4]\n",
    "contact_Bi  = data[data['True_class_labels'] == 5]\n",
    "semi_det_Bi = data[data['True_class_labels'] == 6]\n",
    "rot         = data[data['True_class_labels'] == 7]\n",
    "LPV         = data[data['True_class_labels'] == 8]\n",
    "delta_scuti = data[data['True_class_labels'] == 9]\n",
    "ACEP        = data[data['True_class_labels'] == 10]\n",
    "#misc        = data[data['True_class_labels'] == 11]\n",
    "cep_ii      = data[data['True_class_labels'] == 12]\n",
    "#LMC_cep     = data[data['True_class_labels'] == 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eclipsing_binary: (9018, 9)\n",
      "pulsating: (10489, 9)\n",
      "rotational: (3636, 9)\n"
     ]
    }
   ],
   "source": [
    "eclipsing_binary       =  pd.concat([contact_Bi, semi_det_Bi], axis=0)\n",
    "eclipsing_binary_class = np.full(len(eclipsing_binary), 20, dtype=int)\n",
    "\n",
    "rotational       = rot\n",
    "rotational_class = np.full(len(rotational), 21, dtype=int)\n",
    "\n",
    "pulsating       = pd.concat([RRab, RRc, RRd, blazhko, LPV, delta_scuti, ACEP, cep_ii] ,axis=0)\n",
    "pulsating_class = np.full(len(pulsating), 22, dtype=int)\n",
    "\n",
    "#miscellaneous       = misc\n",
    "#miscellaneous_class = np.full(len(miscellaneous ), 23, dtype=int)\n",
    "\n",
    "print(\"eclipsing_binary: %s\" % str(eclipsing_binary.shape))\n",
    "print(\"pulsating: %s\" % str(pulsating.shape))\n",
    "print(\"rotational: %s\" % str(rotational.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the first layer of the Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Sigma</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Period</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Mean Variance</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>True_class_labels</th>\n",
       "      <th>New_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8750</th>\n",
       "      <td>-0.266203</td>\n",
       "      <td>16.68942</td>\n",
       "      <td>0.160893</td>\n",
       "      <td>-0.207532</td>\n",
       "      <td>0.918550</td>\n",
       "      <td>0.304700</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>3021001008400</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8751</th>\n",
       "      <td>0.045139</td>\n",
       "      <td>15.09758</td>\n",
       "      <td>0.078132</td>\n",
       "      <td>-0.931716</td>\n",
       "      <td>0.288279</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>3021005001789</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8752</th>\n",
       "      <td>0.358397</td>\n",
       "      <td>13.44083</td>\n",
       "      <td>0.097373</td>\n",
       "      <td>-1.108867</td>\n",
       "      <td>0.339740</td>\n",
       "      <td>0.158833</td>\n",
       "      <td>0.007245</td>\n",
       "      <td>3021005010437</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8753</th>\n",
       "      <td>0.455166</td>\n",
       "      <td>14.44517</td>\n",
       "      <td>0.079265</td>\n",
       "      <td>-0.837366</td>\n",
       "      <td>0.238434</td>\n",
       "      <td>0.134741</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>3021005012689</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8754</th>\n",
       "      <td>-0.212264</td>\n",
       "      <td>13.56234</td>\n",
       "      <td>0.127824</td>\n",
       "      <td>-1.363327</td>\n",
       "      <td>0.884521</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>3021006008938</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Skew      Mean     Sigma  Kurtosis    Period  Amplitude  \\\n",
       "8750 -0.266203  16.68942  0.160893 -0.207532  0.918550   0.304700   \n",
       "8751  0.045139  15.09758  0.078132 -0.931716  0.288279   0.136700   \n",
       "8752  0.358397  13.44083  0.097373 -1.108867  0.339740   0.158833   \n",
       "8753  0.455166  14.44517  0.079265 -0.837366  0.238434   0.134741   \n",
       "8754 -0.212264  13.56234  0.127824 -1.363327  0.884521   0.193000   \n",
       "\n",
       "      Mean Variance      File_Name  True_class_labels  New_label  \n",
       "8750       0.009640  3021001008400                  5         20  \n",
       "8751       0.005175  3021005001789                  5         20  \n",
       "8752       0.007245  3021005010437                  5         20  \n",
       "8753       0.005487  3021005012689                  5         20  \n",
       "8754       0.009425  3021006008938                  5         20  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.concat([eclipsing_binary, rotational, pulsating], axis=0)\n",
    "new_class = np.concatenate((eclipsing_binary_class, rotational_class, pulsating_class), axis=0)\n",
    "\n",
    "hierarchy_data = pd.DataFrame(new_data)\n",
    "hierarchy_data['New_label'] = new_class\n",
    "hierarchy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_normalization(hierarchy_data):\n",
    "    # Important: Before performing normalization and any preprocessing on the data- We need to split the data into training and testing sets\n",
    "    # _np stands for: No preprocessing\n",
    "    X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(hierarchy_data.iloc[:,0:9], hierarchy_data.iloc[:,9], test_size=.3,random_state=0)\n",
    "    print(\"X_train_np shape: {}\".format(X_train_np.shape))\n",
    "    print(\"y_train_np shape: {}\".format(y_train_np.shape))\n",
    "    print(\"X_test_np shape: {}\".format(X_test_np.shape))\n",
    "    print(\"y_test_np shape: {}\".format(y_test_np.shape))\n",
    "    \n",
    "    filename_Xtrain = X_train_np['File_Name']\n",
    "    filename_Xtest  = X_test_np['File_Name']\n",
    "    True_class_label_X_train = X_train_np['True_class_labels']\n",
    "    True_class_label_X_test = X_test_np['True_class_labels']\n",
    "    \n",
    "    # Finding the maximum of x_train. Normalisation = |X/max(X_train)| where X is the values of x's in training set and test set\n",
    "    # Take the absolute values so that all is positive\n",
    "    x_train_max  = X_train_np.iloc[:,0:7].max(axis=0)\n",
    "    X_train_norm = X_train_np.iloc[:,0:7].divide(x_train_max, axis=1).abs()\n",
    "    X_train_norm.describe()\n",
    "    \n",
    "    X_test_norm = X_test_np.iloc[:,0:7].divide(x_train_max, axis=1).abs()\n",
    "    X_test_norm.describe()\n",
    "    \n",
    "    y_train_norm = y_train_np\n",
    "    y_test_norm = y_test_np\n",
    "    \n",
    "    # Here we build a dataframe that consists of both Normalised X_train and X_test with the labelling anf filenames\n",
    "    normalise_features_merge = pd.concat([ X_train_norm, X_test_norm ], axis=0)\n",
    "    normalise_filenames      = pd.concat([ filename_Xtrain, filename_Xtest ], axis=0)\n",
    "    true_class_label         = pd.concat([ True_class_label_X_train, True_class_label_X_test ], axis=0)\n",
    "    normalise_classes_merge  = pd.concat([y_train_norm, y_test_norm], axis=0)\n",
    "\n",
    "    print(\"Datasets shape: %s\" % str(normalise_features_merge .shape))\n",
    "    print(\"FileName (Datasets) shape: %s\" % str(normalise_filenames.shape))\n",
    "    print(\"True label shape: %s\" % str(normalise_classes_merge.shape))\n",
    "\n",
    "    data_1 = pd.concat([normalise_features_merge , normalise_classes_merge,normalise_filenames, true_class_label],  axis=1)\n",
    "    #data_1= data_1.rename(columns = {0:'Skew',1:'Mean',2:'Sigma', 3:'Kurtosis', 4:'Period LS', 5:'Amplitude', 6:'Mean Variance', 7:'True_class_labels', 8:'File_Name'})\n",
    "    data_1.head()\n",
    "    return X_train_np, X_test_np, y_train_np, y_test_np, X_train_norm, X_test_norm, y_train_norm, y_test_norm, data_1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gridsearch(classifer, param_grid, n_iter, cv, filename='./results'):\n",
    "    grid  = RandomizedSearchCV(classifer, param_grid, n_iter = n_iter, cv = cv, scoring = \"accuracy\", n_jobs = -1,random_state=1)\n",
    "    grid.fit(X_train,y_train)\n",
    "    opt_parameters = grid.best_params_\n",
    "    print(grid.best_params_)\n",
    "    \n",
    "    params_file = open(filename, 'w')\n",
    "    params_file.write(str(grid.best_params_))\n",
    "    params_file.close()\n",
    "    return opt_parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_save(classifier_optimize, X_train, y_train, filename_model):\n",
    "    fit_model      = classifier_optimize.fit(X_train, y_train)\n",
    "    pickle.dump(fit_model, open(filename_model, 'wb'))\n",
    "\n",
    "def model_fit(filename_model, X_train, y_train, X_test, y_test, classifier_model='Random Forest Classifier',classes=[\"Type 1\" , \"Type 2\"], filename ='./results/'):\n",
    "    #fit_model      = classifier_optimize.fit(X_train, y_train)\n",
    "    fit_model      = pickle.load(open(filename_model, 'rb'))\n",
    "    ypred          = fit_model.predict(X_test)\n",
    "    probability    = fit_model.predict_proba(X_test)\n",
    "    accuracy       = accuracy_score(ypred, y_test)\n",
    "    MCC            = matthews_corrcoef(y_test, ypred)\n",
    "    conf_mat       = confusion_matrix(y_test, ypred)\n",
    "    \n",
    "\n",
    "    \n",
    "    misclassified     = np.where(y_test != ypred)[0]\n",
    "\n",
    "    \n",
    "    name_file = open(filename + \".txt\", 'w')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.write('******* Testing Phase '+ str(classifier_model) +' for ' + str(classes) + ' *******\\n')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.write(\"Accuracy: \"                    + \"%f\" % float(accuracy) + '\\n')\n",
    "    name_file.write(\"Mathews Correlation Coef: \"    + \"%f\" % float(MCC)      + '\\n')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.write('Classification Report\\n')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.write(classification_report(y_test, ypred, target_names = classes)+'\\n')\n",
    "    name_file.write('='*80+'\\n')\n",
    "    name_file.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return fit_model, ypred, probability, conf_mat, misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_probability(X_test, y_test, probability, filename):\n",
    "\n",
    "    proba = pd.DataFrame(y_test)\n",
    "    for i in range(probability.shape[1]):\n",
    "        proba[str(i)]    =  probability[:,i]\n",
    "\n",
    "    proba_df = pd.concat([X_test , proba], axis=1)\n",
    "    proba_df = proba_df.rename(columns = {0:'Skew',1:'Mean',2:'Sigma', 3:'Kurtosis', \\\n",
    "                            4:'Period LS', 5:'Amplitude', 6:'Mean Variance', \n",
    "                            7:'True_class_labels'})\n",
    "\n",
    "    proba_df.to_csv(filename, sep=' ', index=True)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def feature_importance(fit_model, feature_list, feature_imp_dir):\n",
    "    plt.figure(figsize=figSize)\n",
    "    my_colors = list(islice(cycle(['b', 'orange', 'gold', 'purple', 'y', 'brown', 'pink','cyan', 'olive','green', 'gray', 'r', 'k']), None, len(feature_list)))\n",
    "\n",
    "    feat_importances = pd.Series(fit_model.feature_importances_, index=feature_list)\n",
    "    ax = feat_importances.nlargest(7).plot(kind='bar',color=my_colors)\n",
    "    ax.set_title('Feature Importances', fontsize = fontSize)\n",
    "    ax.set_xlabel('Features', fontsize = fontSize)\n",
    "    ax.set_ylabel('Relative Importance', fontsize = fontSize)\n",
    "    ax.tick_params(axis='both', labelsize=fontSize)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(feature_imp_dir)\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_decision_surface(clf, X_train, y_train, X_test, y_test, classifier_model='Random Forest Classifier',\\\n",
    "                          classes_types=[\"Type 1\" , \"Type 2\"], filename ='./results/', \\\n",
    "                          savedir_decision='./decision_boundary_plots/'):\n",
    "    \n",
    "    plot_step = 0.1\n",
    "    if X_train.shape[1] != 2:\n",
    "        raise ValueError('X_train should have exactly two columns or features')\n",
    "\n",
    "    x_min, x_max = X_train[:,0].min() - plot_step, X_train[:,0].max() + plot_step\n",
    "    y_min, y_max = X_train[:,1].min() - plot_step, X_train[:,1].max() + plot_step\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step))\n",
    "    \n",
    "    fit_model      = clf.fit(X_train, y_train)\n",
    "    #score         = clf.score(X_test, y_test)\n",
    "    ypred          = fit_model.predict(X_test)\n",
    "    probability    = fit_model.predict_proba(X_test)\n",
    "    accuracy       = accuracy_score(y_test, ypred)\n",
    "    MCC            = matthews_corrcoef(y_test, ypred)\n",
    "    conf_mat       = confusion_matrix(y_test, ypred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    \n",
    "    misclassified     = np.where(y_test != ypred)[0]\n",
    "\n",
    "    \n",
    "    name_file = open(filename + \".txt\", 'w')\n",
    "    name_file.write('==================================================================================\\n')\n",
    "    name_file.write('******* Testing Phase '+ str(classifier_model) +' for ' + str(classes_types) + ' *******\\n')\n",
    "    name_file.write('==================================================================================\\n')\n",
    "    name_file.write(\"Accuracy: \"                    + \"%f\" % float(accuracy) + '\\n')\n",
    "    name_file.write(\"Mathews Correlation Coef: \"    + \"%f\" % float(MCC)      + '\\n')\n",
    "    name_file.write('=====================================================================================\\n')\n",
    "    name_file.write('=====================================================================================\\n')\n",
    "    name_file.write('Classification Report\\n')\n",
    "    name_file.write('=====================================================================================\\n')\n",
    "    name_file.write(classification_report(y_test, ypred, target_names = classes_types)+'\\n')\n",
    "    name_file.write('=====================================================================================\\n')\n",
    "    name_file.close()\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    if hasattr(fit_model, 'predict_proba'):\n",
    "        Z = fit_model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, nClasses]\n",
    "    else:\n",
    "        Z = fit_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = fit_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \"\"\"\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF', '#FFAAAA'])\n",
    "    \n",
    "    cs = plt.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "    \"\"\"\n",
    "    cs = plt.contourf(xx, yy, Z, alpha=.7)\n",
    "    #plt.scatter(X_train[:,0], X_train[:,1], c=y_train)#, cmap=cm_bright)\n",
    "    plt.scatter(X_test[:,0], X_test[:,1], c=y_test, alpha=0.5, marker='*', edgecolors='black', s=80)#, cmap=cm_bright\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    #plt.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),size=15, horizontalalignment='right')\n",
    "    plt.savefig(savedir_decision)\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    return fit_model, ypred, probability , conf_mat, misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_misclassification(misclassified , data=data, save_dir=r'c:\\data\\np.txt'):\n",
    "    misclassified_list = []\n",
    "    for i in misclassified:\n",
    "        miscal_index = y_test.index[i]\n",
    "        file         = data.loc[miscal_index]\n",
    "        misclassified_list.append(file)\n",
    "    misclassified_data = pd.DataFrame(misclassified_list)\n",
    "    #new_DF = data.drop(misclassified_data.index)\n",
    "    #misclassified_data = misclassified_data.rename(columns = {0:'Skew',1:'Mean',2:'Sigma', 3:'Kurtosis', \\\n",
    "                           # 4:'Period LS', 5:'Amplitude', 6:'Mean Variance', \n",
    "                           # 7:'True_class_labels', 8:'File_names'})\n",
    "    #np.savetxt(save_dir, misclassified_data.values, fmt='%5s', delimiter=\"\\t\",header=\"Skew\\tMean\\tSigma\\tKurtosis\\tPeriod_LS\\tAmplitude\\tMean Variance\\tTrue_class_label\\tFile_names\")\n",
    "    misclassified_data.to_csv(save_dir, sep=' ', index=True)\n",
    "    return misclassified_data#, new_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes_types,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "\n",
    "    print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=16)\n",
    "    cb=plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    cb.ax.tick_params(labelsize=16)\n",
    "    tick_marks = np.arange(len(classes_types))\n",
    "    plt.xticks(tick_marks, classes_types, rotation=45)\n",
    "    plt.yticks(tick_marks, classes_types)\n",
    "    plt.tick_params(axis='x', labelsize=16)\n",
    "    plt.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"black\" if cm[i, j] > thresh else \"black\",fontsize=22)\n",
    "\n",
    "    \n",
    "    plt.ylabel('True label',fontsize = 16)\n",
    "    plt.xlabel('Predicted label', fontsize = 16)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot(conf_mat, classes_types, classifier_model, plot_title, X_test, y_test, nClasses):\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    \n",
    "    plot_confusion_matrix(conf_mat, classes_types, normalize=True, title='Confusion matrix for ' + str(classifier_model) )\n",
    "    plt.savefig(plot_title +'_CM.pdf')\n",
    "    plt.close()\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plot_ROC_curve(X_test, y_test, nClasses, fit_model, title='ROC curve for ' + str(classifier_model) )\n",
    "    plt.savefig(plot_title +'_ROC.pdf')\n",
    "    plt.close()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_tree(tree, feature_names, class_names, dotfile_name='decision_tree'):\n",
    "    \"\"\"Create tree png using graphviz.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    tree -- scikit-learn DecsisionTree.\n",
    "    feature_names -- list of feature names.\n",
    "    \"\"\"\n",
    "    #with open(\"dt.dot\", 'w') as f:\n",
    "        #export_graphviz(tree, out_file=f, feature_names=feature_names)\n",
    "    dotfile = open(dotfile_name+\".dot\", 'w')\n",
    "    dot_data = export_graphviz(tree, out_file=None, \n",
    "                     feature_names=feature_names, class_names=class_names,filled=True, rounded=True,  \n",
    "                     special_characters=True, precision=9) \n",
    "    graph = graphviz.Source(dot_data) \n",
    "    graph.format = 'png'\n",
    "    graph.render(dotfile_name+'_render',view=False)\n",
    "    dotfile.close()\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def analysis_rf(X_train, y_train, types, layer='_layer1'):\n",
    "    n_estimators      = np.arange(50,1000,100)\n",
    "    max_features      = ['auto', 'sqrt', 'log2']\n",
    "    min_samples_split = np.arange(1,20,1)\n",
    "    #max_depth         = np.arange(1,10,2)\n",
    "    param_grid        = dict(n_estimators=n_estimators, max_features=max_features, \\\n",
    "                              min_samples_split=min_samples_split)#,max_depth=max_depth\n",
    "\n",
    "        \n",
    "    opt_parameters_rf = gridsearch(RandomForestClassifier(), param_grid, n_iter = 10, cv = 5, filename= results_dir + types + layer + '_RF_hyparameters.txt')\n",
    "    model_save(RandomForestClassifier(**opt_parameters_rf), X_train=X_train, y_train=y_train, filename_model= results_dir + types + layer + '_RF_model.sav')\n",
    "    return opt_parameters_rf\n",
    "\n",
    "def final_prediction(layer, X_train, y_train, X_test, y_test, classes, types,data, nClasses):\n",
    "\n",
    "    ## when using ONLY Normalisation:\n",
    "    fit_model, ypred, probability, conf_mat, misclassified  = model_fit(filename_model= results_dir + types + layer + '_RF_model.sav', X_train=X_train, y_train=y_train, X_test = X_test, y_test=y_test,\\\n",
    "                                                 classifier_model='Random Forest Classifier',classes=classes, filename =results_dir + types + layer + '_RF')\n",
    "\n",
    "\n",
    "    save_probability(X_test, y_test, probability, filename= results_dir + types+ layer + '_RF_prob.txt')\n",
    "\n",
    "    plotting = plot(conf_mat, classes_types=classes, classifier_model='Random Forest Classifier',\\\n",
    "                                  plot_title= plots_dir + types + layer + '_RF', X_test=X_test, y_test=y_test, nClasses=nClasses)\n",
    "\n",
    "    misclassified_data=find_misclassification(misclassified, data=data, save_dir = misclassify_dir + types + layer + '_RF.txt')\n",
    "\n",
    "    data_feature_names = [ 'Skew', 'Mean',  'Sigma', 'Kurtosis', \"Period\", \"Amplitude\", \"Mean Variance\" ] # No dimensionality Reduction\n",
    "\n",
    "    visualize_tree(fit_model.estimators_[5],data_feature_names, classes, dotfile_name=dotfile_dir+types+'_RF')\n",
    "    #feature_list = [ 'Skew', 'Mean',  'Sigma', 'Kurtosis', \"Period_LS\", \"Amplitude\", \"Mean Variance\" ] # No dimensionality Reduction\n",
    "    feature_imp = feature_importance(fit_model, data_feature_names , feature_imp_dir= plots_dir + types +layer + '_Feature_Importance_RF.pdf')\n",
    "\n",
    "    return fit_model, ypred, probability, conf_mat, misclassified, misclassified_data, feature_imp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training First Layer and output the performance of the Multi-class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_np shape: (16200, 9)\n",
      "y_train_np shape: (16200,)\n",
      "X_test_np shape: (6943, 9)\n",
      "y_test_np shape: (6943,)\n",
      "Datasets shape: (23143, 7)\n",
      "FileName (Datasets) shape: (23143,)\n",
      "True label shape: (23143,)\n",
      "[(3051, 9), (2619, 9), (362, 9), (116, 9), (3129, 9), (3120, 9), (2585, 9), (896, 9), (104, 9), (108, 9), (0, 9), (110, 9), (0, 9)]\n",
      "[(1274, 9), (1133, 9), (140, 9), (55, 9), (1380, 9), (1389, 9), (1051, 9), (390, 9), (43, 9), (45, 9), (0, 9), (43, 9), (0, 9)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Sigma</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Period</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Mean Variance</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>True_class_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>-1.279161</td>\n",
       "      <td>16.81014</td>\n",
       "      <td>0.231949</td>\n",
       "      <td>2.866022</td>\n",
       "      <td>0.586645</td>\n",
       "      <td>0.380330</td>\n",
       "      <td>0.013798</td>\n",
       "      <td>3043082017358</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18317</th>\n",
       "      <td>-2.087279</td>\n",
       "      <td>11.97182</td>\n",
       "      <td>0.116820</td>\n",
       "      <td>17.869820</td>\n",
       "      <td>1.169413</td>\n",
       "      <td>0.171950</td>\n",
       "      <td>0.009758</td>\n",
       "      <td>3027039002850</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606</th>\n",
       "      <td>-0.580564</td>\n",
       "      <td>14.03974</td>\n",
       "      <td>0.100826</td>\n",
       "      <td>0.607546</td>\n",
       "      <td>0.619593</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>3021150002194</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21727</th>\n",
       "      <td>0.969373</td>\n",
       "      <td>10.83396</td>\n",
       "      <td>0.318495</td>\n",
       "      <td>0.373831</td>\n",
       "      <td>109.902187</td>\n",
       "      <td>0.651225</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>3029133056611</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>-0.496068</td>\n",
       "      <td>15.63910</td>\n",
       "      <td>0.172747</td>\n",
       "      <td>1.070978</td>\n",
       "      <td>0.537902</td>\n",
       "      <td>0.406425</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>3029109068258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Skew      Mean     Sigma   Kurtosis      Period  Amplitude  \\\n",
       "2982  -1.279161  16.81014  0.231949   2.866022    0.586645   0.380330   \n",
       "18317 -2.087279  11.97182  0.116820  17.869820    1.169413   0.171950   \n",
       "9606  -0.580564  14.03974  0.100826   0.607546    0.619593   0.170300   \n",
       "21727  0.969373  10.83396  0.318495   0.373831  109.902187   0.651225   \n",
       "1138  -0.496068  15.63910  0.172747   1.070978    0.537902   0.406425   \n",
       "\n",
       "       Mean Variance      File_Name  True_class_labels  \n",
       "2982        0.013798  3043082017358                  1  \n",
       "18317       0.009758  3027039002850                  7  \n",
       "9606        0.007182  3021150002194                  5  \n",
       "21727       0.029398  3029133056611                  8  \n",
       "1138        0.011046  3029109068258                  1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Section Needs to be changed each time\n",
    "classes_types_layer1=[\"Eclipsing\", \"Rotational\", \"Pulsating\"]\n",
    "types_layer1 ='TypeEcl_Rot_Pul'\n",
    "nClasses_layer1=3\n",
    "layer='_layer1'\n",
    "X_train_np, X_test_np, y_train_np, y_test_np, X_train_1, X_test_1, y_train_1, y_test_1, data_1 = split_normalization(hierarchy_data=hierarchy_data)\n",
    "\n",
    "source_count_train = []\n",
    "source_count_test = []\n",
    "for i in range(13):\n",
    "    number_train = X_train_np[X_train_np['True_class_labels'] == i+1].shape\n",
    "    number_test  = X_test_np[X_test_np['True_class_labels'] == i+1].shape\n",
    "    source_count_train.append(number_train)\n",
    "    source_count_test.append(number_test)\n",
    "print(source_count_train)\n",
    "print(source_count_test)\n",
    "\n",
    "X_train=X_train_1; X_test=X_test_1; y_train=y_train_1; y_test=y_test_1\n",
    "X_train_np.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'log2', 'n_estimators': 450, 'min_samples_split': 7}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 'log2', 'min_samples_split': 7, 'n_estimators': 450}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_rf(X_train,y_train, types_layer1,layer=layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.78187071 0.08270134 0.13542795]\n",
      " [0.25880114 0.55946717 0.18173168]\n",
      " [0.10182517 0.02337496 0.87479987]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/matplotlib/font_manager.py:1238: UserWarning: findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/matplotlib/font_manager.py:1238: UserWarning: findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/matplotlib/font_manager.py:1238: UserWarning: findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fit_model1, ypred1, probability1, conf_mat1, misclassified1, misclassified_data1, feature_imp1=final_prediction(layer='_layer1', X_train=X_train, y_train=y_train, \\\n",
    "                     X_test= X_test, y_test=y_test,classes=classes_types_layer1, types=types_layer1,data=data, nClasses=nClasses_layer1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Layer Classification: RRLyrae, LPV, Cepheids, Delta-Scuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Sigma</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Period</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Mean Variance</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>True_class_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>-1.279161</td>\n",
       "      <td>16.81014</td>\n",
       "      <td>0.231949</td>\n",
       "      <td>2.866022</td>\n",
       "      <td>0.586645</td>\n",
       "      <td>0.380330</td>\n",
       "      <td>0.013798</td>\n",
       "      <td>3043082017358</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>-0.496068</td>\n",
       "      <td>15.63910</td>\n",
       "      <td>0.172747</td>\n",
       "      <td>1.070978</td>\n",
       "      <td>0.537902</td>\n",
       "      <td>0.406425</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>3029109068258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>-0.796654</td>\n",
       "      <td>15.12869</td>\n",
       "      <td>0.084144</td>\n",
       "      <td>4.431087</td>\n",
       "      <td>0.644810</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>3043005012346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>-1.469637</td>\n",
       "      <td>16.96711</td>\n",
       "      <td>0.132514</td>\n",
       "      <td>11.740510</td>\n",
       "      <td>0.656586</td>\n",
       "      <td>0.213650</td>\n",
       "      <td>0.007810</td>\n",
       "      <td>3023107021048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>-0.782262</td>\n",
       "      <td>17.17891</td>\n",
       "      <td>0.284223</td>\n",
       "      <td>0.902383</td>\n",
       "      <td>0.550643</td>\n",
       "      <td>0.504350</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>3069020017838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Skew      Mean     Sigma   Kurtosis    Period  Amplitude  \\\n",
       "2982 -1.279161  16.81014  0.231949   2.866022  0.586645   0.380330   \n",
       "1138 -0.496068  15.63910  0.172747   1.070978  0.537902   0.406425   \n",
       "2867 -0.796654  15.12869  0.084144   4.431087  0.644810   0.145200   \n",
       "403  -1.469637  16.96711  0.132514  11.740510  0.656586   0.213650   \n",
       "4231 -0.782262  17.17891  0.284223   0.902383  0.550643   0.504350   \n",
       "\n",
       "      Mean Variance      File_Name  True_class_labels  \n",
       "2982       0.013798  3043082017358                  1  \n",
       "1138       0.011046  3029109068258                  1  \n",
       "2867       0.005562  3043005012346                  1  \n",
       "403        0.007810  3023107021048                  1  \n",
       "4231       0.016545  3069020017838                  1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RRab_xtrain_2        = X_train_np[X_train_np['True_class_labels'] == 1]\n",
    "RRc_xtrain_2         = X_train_np[X_train_np['True_class_labels'] == 2]\n",
    "RRd_xtrain_2         = X_train_np[X_train_np['True_class_labels'] == 3]\n",
    "Blazhko_xtrain_2     = X_train_np[X_train_np['True_class_labels'] == 4]\n",
    "EB_xtrain_2          = X_train_np[X_train_np['True_class_labels'] == 5]\n",
    "EA_xtrain_2          = X_train_np[X_train_np['True_class_labels'] == 6]\n",
    "LPV_xtrain_2         = X_train_np[X_train_np['True_class_labels'] == 8]\n",
    "delta_scuti_xtrain_2 = X_train_np[X_train_np['True_class_labels'] == 9]\n",
    "ACEP_xtrain_2        = X_train_np[X_train_np['True_class_labels'] == 10]\n",
    "LMC_Cep_II_xtrain_2  = X_train_np[X_train_np['True_class_labels'] == 12]\n",
    "\n",
    "\n",
    "RRab_xtest_2        = X_test_np[X_test_np['True_class_labels'] == 1]\n",
    "RRc_xtest_2         = X_test_np[X_test_np['True_class_labels'] == 2]\n",
    "RRd_xtest_2         = X_test_np[X_test_np['True_class_labels'] == 3]\n",
    "Blazhko_xtest_2     = X_test_np[X_test_np['True_class_labels'] == 4]\n",
    "EB_xtest_2          = X_test_np[X_test_np['True_class_labels'] == 5]\n",
    "EA_xtest_2          = X_test_np[X_test_np['True_class_labels'] == 6]\n",
    "LPV_xtest_2         = X_test_np[X_test_np['True_class_labels'] == 8]\n",
    "delta_scuti_xtest_2 = X_test_np[X_test_np['True_class_labels'] == 9]\n",
    "ACEP_xtest_2        = X_test_np[X_test_np['True_class_labels'] == 10]\n",
    "LMC_Cep_II_xtest_2  = X_test_np[X_test_np['True_class_labels'] == 12]\n",
    "\n",
    "RRab_xtrain_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/envs/tflearn/lib/python3.5/site-packages/ipykernel/__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "RRab_ytrain_2 = np.full(len(RRab_xtrain_2), 29, dtype=int)\n",
    "RRab_xtrain_2['label'] = RRab_ytrain_2\n",
    "\n",
    "RRc_ytrain_2 = np.full(len(RRc_xtrain_2), 30, dtype=int)\n",
    "RRc_xtrain_2['label'] = RRc_ytrain_2\n",
    "\n",
    "RRd_ytrain_2 = np.full(len(RRd_xtrain_2), 31, dtype=int)\n",
    "RRd_xtrain_2['label'] = RRd_ytrain_2\n",
    "Blazhko_ytrain_2 = np.full(len(Blazhko_xtrain_2), 32, dtype=int)\n",
    "Blazhko_xtrain_2['label'] = Blazhko_ytrain_2\n",
    "EB_ytrain_2 = np.full(len(EB_xtrain_2), 23, dtype=int)\n",
    "EB_xtrain_2['label'] = EB_ytrain_2\n",
    "EA_ytrain_2 = np.full(len(EA_xtrain_2), 24, dtype=int)\n",
    "EA_xtrain_2['label'] = EA_ytrain_2\n",
    "LPV_ytrain_2 = np.full(len(LPV_xtrain_2), 26, dtype=int)\n",
    "LPV_xtrain_2['New_label'] = LPV_ytrain_2\n",
    "delta_scuti_ytrain_2 = np.full(len(delta_scuti_xtrain_2), 28, dtype=int)\n",
    "delta_scuti_xtrain_2['New_label'] = delta_scuti_ytrain_2\n",
    "ACEP_ytrain_2 = np.full(len(ACEP_xtrain_2), 33, dtype=int)\n",
    "ACEP_xtrain_2['label'] = ACEP_ytrain_2\n",
    "LMC_Cep_II_ytrain_2 = np.full(len(LMC_Cep_II_xtrain_2), 34, dtype=int)\n",
    "LMC_Cep_II_xtrain_2['label'] = LMC_Cep_II_ytrain_2\n",
    "\n",
    "RRab_ytest_2 = np.full(len(RRab_xtest_2), 29, dtype=int)\n",
    "RRab_xtest_2['label'] = RRab_ytest_2\n",
    "RRc_ytest_2 = np.full(len(RRc_xtest_2), 30, dtype=int)\n",
    "RRc_xtest_2['label'] = RRc_ytest_2\n",
    "RRd_ytest_2 = np.full(len(RRd_xtest_2), 31, dtype=int)\n",
    "RRd_xtest_2['label'] = RRd_ytest_2\n",
    "Blazhko_ytest_2 = np.full(len(Blazhko_xtest_2), 32, dtype=int)\n",
    "Blazhko_xtest_2['label'] = Blazhko_ytest_2\n",
    "EB_ytest_2 = np.full(len(EB_xtest_2), 23, dtype=int)\n",
    "EB_xtest_2['label'] = EB_ytest_2\n",
    "EA_ytest_2 = np.full(len(EA_xtest_2), 24, dtype=int)\n",
    "EA_xtest_2['label'] = EA_ytest_2\n",
    "LPV_ytest_2 = np.full(len(LPV_xtest_2), 26, dtype=int)\n",
    "LPV_xtest_2['New_label'] = LPV_ytest_2\n",
    "delta_scuti_ytest_2 = np.full(len(delta_scuti_xtest_2), 28, dtype=int)\n",
    "delta_scuti_xtest_2['New_label'] = delta_scuti_ytest_2\n",
    "ACEP_ytest_2 = np.full(len(ACEP_xtest_2), 33, dtype=int)\n",
    "ACEP_xtest_2['label'] = ACEP_ytest_2\n",
    "LMC_Cep_II_ytest_2 = np.full(len(LMC_Cep_II_xtest_2), 34, dtype=int)\n",
    "LMC_Cep_II_xtest_2['label'] = LMC_Cep_II_ytest_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR Lyrae: (6148, 10)\n",
      "Long Period Variable : (896, 10)\n",
      "Cepheid: (218, 10)\n",
      "Delta Scuti: (104, 10)\n",
      "RR Lyrae: (2602, 10)\n",
      "Long Period Variable : (390, 10)\n",
      "Cepheid: (88, 10)\n",
      "Delta Scuti: (43, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Sigma</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Period</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Mean Variance</th>\n",
       "      <th>File_Name</th>\n",
       "      <th>True_class_labels</th>\n",
       "      <th>New_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22770</th>\n",
       "      <td>0.210635</td>\n",
       "      <td>15.45497</td>\n",
       "      <td>0.094071</td>\n",
       "      <td>1.406561</td>\n",
       "      <td>0.091157</td>\n",
       "      <td>0.170625</td>\n",
       "      <td>0.006087</td>\n",
       "      <td>3039078014633</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22718</th>\n",
       "      <td>-0.368299</td>\n",
       "      <td>13.22244</td>\n",
       "      <td>0.179907</td>\n",
       "      <td>-0.058215</td>\n",
       "      <td>0.160254</td>\n",
       "      <td>0.295025</td>\n",
       "      <td>0.013606</td>\n",
       "      <td>3029133042134</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22696</th>\n",
       "      <td>-0.037838</td>\n",
       "      <td>14.48072</td>\n",
       "      <td>0.062780</td>\n",
       "      <td>-1.052647</td>\n",
       "      <td>0.098020</td>\n",
       "      <td>0.100480</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>3023046071881</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22723</th>\n",
       "      <td>0.053418</td>\n",
       "      <td>16.59224</td>\n",
       "      <td>0.099235</td>\n",
       "      <td>0.437859</td>\n",
       "      <td>0.130054</td>\n",
       "      <td>0.195080</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>3031063008290</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22826</th>\n",
       "      <td>-0.381178</td>\n",
       "      <td>16.10363</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>-0.837405</td>\n",
       "      <td>0.161028</td>\n",
       "      <td>0.235945</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>3057079018243</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Skew      Mean     Sigma  Kurtosis    Period  Amplitude  \\\n",
       "22770  0.210635  15.45497  0.094071  1.406561  0.091157   0.170625   \n",
       "22718 -0.368299  13.22244  0.179907 -0.058215  0.160254   0.295025   \n",
       "22696 -0.037838  14.48072  0.062780 -1.052647  0.098020   0.100480   \n",
       "22723  0.053418  16.59224  0.099235  0.437859  0.130054   0.195080   \n",
       "22826 -0.381178  16.10363  0.134000 -0.837405  0.161028   0.235945   \n",
       "\n",
       "       Mean Variance      File_Name  True_class_labels  New_label  \n",
       "22770       0.006087  3039078014633                  9         28  \n",
       "22718       0.013606  3029133042134                  9         28  \n",
       "22696       0.004335  3023046071881                  9         28  \n",
       "22723       0.005981  3031063008290                  9         28  \n",
       "22826       0.008321  3057079018243                  9         28  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RR_Lyrae_xtrain_2  = pd.concat([RRab_xtrain_2, RRc_xtrain_2, RRd_xtrain_2, Blazhko_xtrain_2],axis=0)\n",
    "RR_Lyrae_xtest_2   = pd.concat([RRab_xtest_2, RRc_xtest_2, RRd_xtest_2, Blazhko_xtest_2],axis=0)\n",
    "RR_Lyrae_xtrain_2  = RR_Lyrae_xtrain_2.drop(['label'], axis=1)\n",
    "RR_Lyrae_xtest_2   = RR_Lyrae_xtest_2.drop(['label'], axis=1)\n",
    "RR_Lyrae_ytrain_2 = np.full(len(RR_Lyrae_xtrain_2), 25, dtype=int)\n",
    "RR_Lyrae_xtrain_2['New_label'] = RR_Lyrae_ytrain_2\n",
    "RR_Lyrae_ytest_2 = np.full(len(RR_Lyrae_xtest_2), 25, dtype=int)\n",
    "RR_Lyrae_xtest_2['New_label'] = RR_Lyrae_ytest_2\n",
    "\n",
    "LPV_xtrain_2 = LPV_xtrain_2\n",
    "LPV_xtest_2  = LPV_xtest_2\n",
    "LPV_ytrain_2= LPV_xtrain_2['New_label']\n",
    "LPV_ytest_2= LPV_xtest_2['New_label']\n",
    "\n",
    "\n",
    "cepheid_xtrain_2       = pd.concat([ACEP_xtrain_2, LMC_Cep_II_xtrain_2] ,axis=0)\n",
    "cepheid_xtest_2       = pd.concat([ACEP_xtest_2, LMC_Cep_II_xtest_2] ,axis=0)\n",
    "cepheid_xtrain_2      = cepheid_xtrain_2.drop(['label'], axis=1)\n",
    "cepheid_xtest_2       = cepheid_xtest_2.drop(['label'], axis=1)\n",
    "cepheid_ytrain_2_class = np.full(len(cepheid_xtrain_2), 27, dtype=int)\n",
    "cepheid_ytest_2_class = np.full(len(cepheid_xtest_2), 27, dtype=int)\n",
    "cepheid_xtrain_2['New_label'] = cepheid_ytrain_2_class\n",
    "cepheid_xtest_2['New_label'] = cepheid_ytest_2_class\n",
    "\n",
    "delta_scuti_xtrain_2 = delta_scuti_xtrain_2\n",
    "delta_scuti_xtest_2 = delta_scuti_xtest_2\n",
    "delta_scuti_ytrain_2= delta_scuti_xtrain_2['New_label']\n",
    "delta_scuti_ytest_2= delta_scuti_xtest_2['New_label']\n",
    "\n",
    "\n",
    "\n",
    "print(\"RR Lyrae: %s\" % str(RR_Lyrae_xtrain_2.shape))\n",
    "print(\"Long Period Variable : %s\" % str(LPV_xtrain_2.shape))\n",
    "print(\"Cepheid: %s\" % str(cepheid_xtrain_2.shape))\n",
    "print(\"Delta Scuti: %s\" % str(delta_scuti_xtrain_2.shape))\n",
    "\n",
    "print(\"RR Lyrae: %s\" % str(RR_Lyrae_xtest_2.shape))\n",
    "print(\"Long Period Variable : %s\" % str(LPV_xtest_2.shape))\n",
    "print(\"Cepheid: %s\" % str(cepheid_xtest_2.shape))\n",
    "print(\"Delta Scuti: %s\" % str(delta_scuti_xtest_2.shape))\n",
    "delta_scuti_xtrain_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_second_layer_pul = pd.concat([RR_Lyrae_xtrain_2, LPV_xtrain_2, cepheid_xtrain_2,  delta_scuti_xtrain_2], axis=0, sort=False)\n",
    "x_test_second_layer_pul = pd.concat([RR_Lyrae_xtest_2, LPV_xtest_2, cepheid_xtest_2,delta_scuti_xtest_2 ], axis=0, sort=False)\n",
    "\n",
    "\n",
    "# Finding the maximum of x_train. Normalisation = |X/max(X_train)| where X is the values of x's in training set and test set\n",
    "# Take the absolute values so that all is positive\n",
    "x_train_second_layer_pul_max  = x_train_second_layer_pul.iloc[:,0:7].max(axis=0)\n",
    "X_train_second_layer_pul_norm = x_train_second_layer_pul.iloc[:,0:7].divide(x_train_second_layer_pul_max, axis=1).abs()\n",
    "\n",
    "\n",
    "X_test_second_layer_pul_norm = x_test_second_layer_pul.iloc[:,0:7].divide(x_train_second_layer_pul_max, axis=1).abs()\n",
    "X_test_second_layer_pul_norm.describe()\n",
    "\n",
    "\n",
    "y_train_second_layer_pul = x_train_second_layer_pul['New_label']\n",
    "y_test_second_layer_pul  = x_test_second_layer_pul['New_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Layer 2 and output the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Section Needs to be changed each time\n",
    "classes_types_layer2=[\"RR Lyrae\", \"LPV\", \"Cepheids\", \"$\\delta$-Scuti\"]\n",
    "types_layer2 ='TypeRRlyrae_LPV_Cepheids_ds'\n",
    "nClasses_layer2=4\n",
    "layer_2='_layer2_pul'\n",
    "\n",
    "X_train=X_train_second_layer_pul_norm\n",
    "X_test=X_test_second_layer_pul_norm\n",
    "y_train=y_train_second_layer_pul\n",
    "y_test=y_test_second_layer_pul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'auto', 'n_estimators': 150, 'min_samples_split': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'min_samples_split': 5, 'n_estimators': 150}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_rf(X_train,y_train, types_layer2, layer=layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[9.94619523e-01 0.00000000e+00 4.61183705e-03 7.68639508e-04]\n",
      " [0.00000000e+00 9.94871795e-01 5.12820513e-03 0.00000000e+00]\n",
      " [1.59090909e-01 1.13636364e-02 8.29545455e-01 0.00000000e+00]\n",
      " [2.32558140e-02 0.00000000e+00 0.00000000e+00 9.76744186e-01]]\n"
     ]
    }
   ],
   "source": [
    "fit_model2, ypred2, probability2, conf_mat2, misclassified2, misclassified_data2, feature_imp2=final_prediction(layer=layer_2, X_train=X_train, y_train=y_train, \\\n",
    "                     X_test= X_test, y_test=y_test,classes=classes_types_layer2, types=types_layer2, data=data, nClasses=nClasses_layer2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 2: Eclipsing Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_second_layer_ecl = pd.concat([EB_xtrain_2,EA_xtrain_2], axis=0, sort=False)\n",
    "x_test_second_layer_ecl = pd.concat([EB_xtest_2, EA_xtest_2], axis=0, sort=False)\n",
    "\n",
    "\n",
    "# Finding the maximum of x_train. Normalisation = |X/max(X_train)| where X is the values of x's in training set and test set\n",
    "# Take the absolute values so that all is positive\n",
    "x_train_second_layer_ecl_max  = x_train_second_layer_ecl.iloc[:,0:7].max(axis=0)\n",
    "X_train_second_layer_ecl_norm = x_train_second_layer_ecl.iloc[:,0:7].divide(x_train_second_layer_ecl_max, axis=1).abs()\n",
    "\n",
    "\n",
    "X_test_second_layer_ecl_norm = x_test_second_layer_ecl.iloc[:,0:7].divide(x_train_second_layer_ecl_max, axis=1).abs()\n",
    "X_test_second_layer_ecl_norm.describe()\n",
    "\n",
    "\n",
    "y_train_second_layer_ecl = x_train_second_layer_ecl['label']\n",
    "y_test_second_layer_ecl  = x_test_second_layer_ecl['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Second Layer: Eclipsing Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Section Needs to be changed each time\n",
    "classes_types_layer2=[\"EB\", \"EA\"]\n",
    "types_layer2 ='TypeEA_EB'\n",
    "nClasses_layer2=2\n",
    "layer_2='_layer2_ecl'\n",
    "\n",
    "X_train=X_train_second_layer_ecl_norm\n",
    "X_test=X_test_second_layer_ecl_norm\n",
    "y_train=y_train_second_layer_ecl\n",
    "y_test=y_test_second_layer_ecl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'sqrt', 'n_estimators': 50, 'min_samples_split': 8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 'sqrt', 'min_samples_split': 8, 'n_estimators': 50}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_rf(X_train,y_train, types_layer2, layer=layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.92463768 0.07536232]\n",
      " [0.08207343 0.91792657]]\n"
     ]
    }
   ],
   "source": [
    "fit_model2_ecl, ypred2_ecl, probability2_ecl, conf_mat2_ecl, misclassified2_ecl, misclassified_data2_ecl, feature_imp2_ecl=final_prediction(layer=layer_2, X_train=X_train, y_train=y_train, \\\n",
    "                     X_test= X_test, y_test=y_test,classes=classes_types_layer2, types=types_layer2, data=data, nClasses=nClasses_layer2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Layer \n",
    "### RR Lyrae Classiffication: RRab, RRc, RRd, Blazhko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Sigma</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Period</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Mean Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6148.000000</td>\n",
       "      <td>6148.000000</td>\n",
       "      <td>6148.000000</td>\n",
       "      <td>6.148000e+03</td>\n",
       "      <td>6148.000000</td>\n",
       "      <td>6148.000000</td>\n",
       "      <td>6148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.047108</td>\n",
       "      <td>0.829970</td>\n",
       "      <td>0.234246</td>\n",
       "      <td>1.738095e-02</td>\n",
       "      <td>0.259776</td>\n",
       "      <td>0.279082</td>\n",
       "      <td>0.225716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.073481</td>\n",
       "      <td>0.073338</td>\n",
       "      <td>0.089668</td>\n",
       "      <td>5.273459e-02</td>\n",
       "      <td>0.080677</td>\n",
       "      <td>0.120261</td>\n",
       "      <td>0.077553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.549400</td>\n",
       "      <td>0.045002</td>\n",
       "      <td>4.189283e-07</td>\n",
       "      <td>0.107749</td>\n",
       "      <td>0.056392</td>\n",
       "      <td>0.051475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.010860</td>\n",
       "      <td>0.779280</td>\n",
       "      <td>0.169838</td>\n",
       "      <td>2.014778e-03</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.185829</td>\n",
       "      <td>0.172207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.025598</td>\n",
       "      <td>0.838762</td>\n",
       "      <td>0.210273</td>\n",
       "      <td>4.434345e-03</td>\n",
       "      <td>0.259306</td>\n",
       "      <td>0.245648</td>\n",
       "      <td>0.205915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.052447</td>\n",
       "      <td>0.887613</td>\n",
       "      <td>0.286426</td>\n",
       "      <td>8.372313e-03</td>\n",
       "      <td>0.328972</td>\n",
       "      <td>0.352699</td>\n",
       "      <td>0.268644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Skew         Mean        Sigma      Kurtosis       Period  \\\n",
       "count  6148.000000  6148.000000  6148.000000  6.148000e+03  6148.000000   \n",
       "mean      0.047108     0.829970     0.234246  1.738095e-02     0.259776   \n",
       "std       0.073481     0.073338     0.089668  5.273459e-02     0.080677   \n",
       "min       0.000004     0.549400     0.045002  4.189283e-07     0.107749   \n",
       "25%       0.010860     0.779280     0.169838  2.014778e-03     0.185500   \n",
       "50%       0.025598     0.838762     0.210273  4.434345e-03     0.259306   \n",
       "75%       0.052447     0.887613     0.286426  8.372313e-03     0.328972   \n",
       "max       1.000000     1.000000     1.000000  1.000000e+00     1.000000   \n",
       "\n",
       "         Amplitude  Mean Variance  \n",
       "count  6148.000000    6148.000000  \n",
       "mean      0.279082       0.225716  \n",
       "std       0.120261       0.077553  \n",
       "min       0.056392       0.051475  \n",
       "25%       0.185829       0.172207  \n",
       "50%       0.245648       0.205915  \n",
       "75%       0.352699       0.268644  \n",
       "max       1.000000       1.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_third_layer_RR = pd.concat([RRab_xtrain_2, RRc_xtrain_2, RRd_xtrain_2, Blazhko_xtrain_2], axis=0, sort=False)\n",
    "x_test_third_layer_RR = pd.concat([RRab_xtest_2, RRc_xtest_2, RRd_xtest_2, Blazhko_xtest_2], axis=0, sort=False)\n",
    "\n",
    "\n",
    "# Finding the maximum of x_train. Normalisation = |X/max(X_train)| where X is the values of x's in training set and test set\n",
    "# Take the absolute values so that all is positive\n",
    "x_train_third_layer_RR_max  = x_train_third_layer_RR.iloc[:,0:7].max(axis=0)\n",
    "X_train_third_layer_RR_norm = x_train_third_layer_RR.iloc[:,0:7].divide(x_train_third_layer_RR_max, axis=1).abs()\n",
    "\n",
    "\n",
    "X_test_third_layer_RR_norm = x_test_third_layer_RR.iloc[:,0:7].divide(x_train_third_layer_RR_max, axis=1).abs()\n",
    "X_test_third_layer_RR_norm.describe()\n",
    "\n",
    "\n",
    "y_train_third_layer_RR = x_train_third_layer_RR['label']\n",
    "y_test_third_layer_RR  = x_test_third_layer_RR['label']\n",
    "\n",
    "X_train_third_layer_RR_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Third Layer RR Lyrae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Section Needs to be changed each time\n",
    "classes_types_layer3=[\"RRab\", \"RRc\", \"RRd\", \"Blazhko\"]\n",
    "types_layer3 ='TypeRRab_RRc_RRd_Blazhko'\n",
    "nClasses_layer3=4\n",
    "layer_3='_layer3_RR'\n",
    "\n",
    "X_train=X_train_third_layer_RR_norm\n",
    "X_test=X_test_third_layer_RR_norm\n",
    "y_train=y_train_third_layer_RR\n",
    "y_test=y_test_third_layer_RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'auto', 'n_estimators': 50, 'min_samples_split': 19}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'min_samples_split': 19, 'n_estimators': 50}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_rf(X_train,y_train, types_layer3, layer=layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[9.99215071e-01 7.84929356e-04 0.00000000e+00 0.00000000e+00]\n",
      " [5.29567520e-03 9.81465137e-01 1.32391880e-02 0.00000000e+00]\n",
      " [7.85714286e-02 7.42857143e-01 1.78571429e-01 0.00000000e+00]\n",
      " [9.81818182e-01 0.00000000e+00 0.00000000e+00 1.81818182e-02]]\n"
     ]
    }
   ],
   "source": [
    "fit_model3_RR, ypred3_RR, probability3_RR, conf_mat3_RR, misclassified3_RR, misclassified_data3_RR, feature_imp3_RR=final_prediction(layer=layer_3, X_train=X_train, y_train=y_train, \\\n",
    "                     X_test= X_test, y_test=y_test,classes=classes_types_layer3, types=types_layer3, data=data, nClasses=nClasses_layer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification for RR Lyrae - RRab and Blazhko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 10)\n",
      "(110, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Balance Dataset\n",
    "x_train_third_layer_RR = pd.concat([RRab_xtrain_2.iloc[0:Blazhko_xtrain_2.shape[0],:], Blazhko_xtrain_2], axis=0, sort=False)\n",
    "x_test_third_layer_RR = pd.concat([RRab_xtest_2.iloc[0:Blazhko_xtest_2.shape[0]], Blazhko_xtest_2], axis=0, sort=False)\n",
    "\n",
    "# another set  of Balance Dataset\n",
    "#x_train_third_layer_RR = pd.concat([RRab_xtrain_2.iloc[Blazhko_xtrain_2.shape[0]:Blazhko_xtrain_2.shape[0]+Blazhko_xtrain_2.shape[0],:], Blazhko_xtrain_2], axis=0, sort=False)\n",
    "#x_test_third_layer_RR = pd.concat([RRab_xtest_2.iloc[Blazhko_xtest_2.shape[0]:Blazhko_xtest_2.shape[0]+Blazhko_xtest_2.shape[0]], Blazhko_xtest_2], axis=0, sort=False)\n",
    "\n",
    "print(x_train_third_layer_RR.shape)\n",
    "print(x_test_third_layer_RR.shape)\n",
    "#Imbalance dataset                                   \n",
    "#x_train_third_layer_RR = pd.concat([RRab_xtrain_2, Blazhko_xtrain_2], axis=0, sort=False)\n",
    "#x_test_third_layer_RR = pd.concat([RRab_xtest_2, Blazhko_xtest_2], axis=0, sort=False)\n",
    "\n",
    "\n",
    "# Finding the maximum of x_train. Normalisation = |X/max(X_train)| where X is the values of x's in training set and test set\n",
    "# Take the absolute values so that all is positive\n",
    "x_train_third_layer_RR_max  = x_train_third_layer_RR.iloc[:,0:7].max(axis=0)\n",
    "X_train_third_layer_RR_norm = x_train_third_layer_RR.iloc[:,0:7].divide(x_train_third_layer_RR_max, axis=1).abs()\n",
    "\n",
    "\n",
    "X_test_third_layer_RR_norm = x_test_third_layer_RR.iloc[:,0:7].divide(x_train_third_layer_RR_max, axis=1).abs()\n",
    "X_test_third_layer_RR_norm.describe()\n",
    "\n",
    "\n",
    "y_train_third_layer_RR = x_train_third_layer_RR['label']\n",
    "y_test_third_layer_RR  = x_test_third_layer_RR['label']\n",
    "\n",
    "#X_train_third_layer_RR_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 7)\n",
      "(110, 7)\n",
      "(232,)\n",
      "(110,)\n"
     ]
    }
   ],
   "source": [
    "# This Section Needs to be changed each time\n",
    "classes_types_layer3=[\"RRab\",\"Blazhko\"]\n",
    "types_layer3 ='TypeRRab_Blazhko_balance'\n",
    "nClasses_layer3=2\n",
    "layer_3='_layer3_RRab_blazhko_balance'\n",
    "\n",
    "X_train=X_train_third_layer_RR_norm\n",
    "X_test=X_test_third_layer_RR_norm\n",
    "y_train=y_train_third_layer_RR\n",
    "y_test=y_test_third_layer_RR\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'auto', 'n_estimators': 150, 'min_samples_split': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'min_samples_split': 5, 'n_estimators': 150}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_rf(X_train,y_train, types_layer3, layer=layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.76363636 0.23636364]\n",
      " [0.09090909 0.90909091]]\n"
     ]
    }
   ],
   "source": [
    "fit_model3_RRab_blaz, ypred3_RRab_blaz, probability3_RRab_blaz, conf_mat3_RRab_blaz, misclassified3_RRab_blaz, misclassified_data3_RRab_blaz, feature_imp3_RRab_blaz=final_prediction(layer=layer_3, X_train=X_train, y_train=y_train, \\\n",
    "                     X_test= X_test, y_test=y_test,classes=classes_types_layer3, types=types_layer3, data=data, nClasses=nClasses_layer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification for RR Lyrae - RRc and RRd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Sigma</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Period</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Mean Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>724.000000</td>\n",
       "      <td>724.000000</td>\n",
       "      <td>724.000000</td>\n",
       "      <td>7.240000e+02</td>\n",
       "      <td>724.000000</td>\n",
       "      <td>724.000000</td>\n",
       "      <td>724.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.091591</td>\n",
       "      <td>0.830371</td>\n",
       "      <td>0.429722</td>\n",
       "      <td>4.223423e-02</td>\n",
       "      <td>0.284167</td>\n",
       "      <td>0.404787</td>\n",
       "      <td>0.434605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.163087</td>\n",
       "      <td>0.069660</td>\n",
       "      <td>0.103919</td>\n",
       "      <td>1.187380e-01</td>\n",
       "      <td>0.055019</td>\n",
       "      <td>0.114175</td>\n",
       "      <td>0.093354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.616449</td>\n",
       "      <td>0.142239</td>\n",
       "      <td>9.629325e-07</td>\n",
       "      <td>0.155124</td>\n",
       "      <td>0.127650</td>\n",
       "      <td>0.150322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.015388</td>\n",
       "      <td>0.785619</td>\n",
       "      <td>0.364401</td>\n",
       "      <td>4.612268e-03</td>\n",
       "      <td>0.253038</td>\n",
       "      <td>0.331709</td>\n",
       "      <td>0.377818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.042650</td>\n",
       "      <td>0.831475</td>\n",
       "      <td>0.408734</td>\n",
       "      <td>9.666758e-03</td>\n",
       "      <td>0.278441</td>\n",
       "      <td>0.378329</td>\n",
       "      <td>0.420124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.086748</td>\n",
       "      <td>0.881563</td>\n",
       "      <td>0.477431</td>\n",
       "      <td>1.761862e-02</td>\n",
       "      <td>0.307594</td>\n",
       "      <td>0.447660</td>\n",
       "      <td>0.479871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.214181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Skew        Mean       Sigma      Kurtosis      Period  \\\n",
       "count  724.000000  724.000000  724.000000  7.240000e+02  724.000000   \n",
       "mean     0.091591    0.830371    0.429722  4.223423e-02    0.284167   \n",
       "std      0.163087    0.069660    0.103919  1.187380e-01    0.055019   \n",
       "min      0.000051    0.616449    0.142239  9.629325e-07    0.155124   \n",
       "25%      0.015388    0.785619    0.364401  4.612268e-03    0.253038   \n",
       "50%      0.042650    0.831475    0.408734  9.666758e-03    0.278441   \n",
       "75%      0.086748    0.881563    0.477431  1.761862e-02    0.307594   \n",
       "max      1.214181    1.000000    1.000000  1.000000e+00    1.000000   \n",
       "\n",
       "        Amplitude  Mean Variance  \n",
       "count  724.000000     724.000000  \n",
       "mean     0.404787       0.434605  \n",
       "std      0.114175       0.093354  \n",
       "min      0.127650       0.150322  \n",
       "25%      0.331709       0.377818  \n",
       "50%      0.378329       0.420124  \n",
       "75%      0.447660       0.479871  \n",
       "max      1.000000       1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imbalance\n",
    "#x_train_third_layer_RR = pd.concat([RRc_xtrain_2, RRd_xtrain_2], axis=0, sort=False)\n",
    "#x_test_third_layer_RR = pd.concat([RRc_xtest_2, RRd_xtest_2], axis=0, sort=False)\n",
    "\n",
    "# balance set\n",
    "x_train_third_layer_RR = pd.concat([RRc_xtrain_2.iloc[0:RRd_xtrain_2.shape[0],:], RRd_xtrain_2], axis=0, sort=False)\n",
    "x_test_third_layer_RR = pd.concat([RRc_xtest_2.iloc[0:RRd_xtest_2.shape[0]], RRd_xtest_2], axis=0, sort=False)\n",
    "\n",
    "\n",
    "# another set of balance\n",
    "#x_train_third_layer_RR = pd.concat([RRc_xtrain_2.iloc[RRd_xtrain_2.shape[0]:RRd_xtrain_2.shape[0]+RRd_xtrain_2.shape[0],:], RRd_xtrain_2], axis=0, sort=False)\n",
    "#x_test_third_layer_RR = pd.concat([RRc_xtest_2.iloc[RRd_xtest_2.shape[0]:RRd_xtest_2.shape[0]+RRd_xtest_2.shape[0]], RRd_xtest_2], axis=0, sort=False)\n",
    "\n",
    "\n",
    "# Finding the maximum of x_train. Normalisation = |X/max(X_train)| where X is the values of x's in training set and test set\n",
    "# Take the absolute values so that all is positive\n",
    "x_train_third_layer_RR_max  = x_train_third_layer_RR.iloc[:,0:7].max(axis=0)\n",
    "X_train_third_layer_RR_norm = x_train_third_layer_RR.iloc[:,0:7].divide(x_train_third_layer_RR_max, axis=1).abs()\n",
    "\n",
    "\n",
    "X_test_third_layer_RR_norm = x_test_third_layer_RR.iloc[:,0:7].divide(x_train_third_layer_RR_max, axis=1).abs()\n",
    "X_test_third_layer_RR_norm.describe()\n",
    "\n",
    "\n",
    "y_train_third_layer_RR = x_train_third_layer_RR['label']\n",
    "y_test_third_layer_RR  = x_test_third_layer_RR['label']\n",
    "\n",
    "X_train_third_layer_RR_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724, 7)\n",
      "(280, 7)\n",
      "(724,)\n",
      "(280,)\n"
     ]
    }
   ],
   "source": [
    "# This Section Needs to be changed each time\n",
    "classes_types_layer3=[\"RRc\", \"RRd\"]\n",
    "types_layer3 ='TypeRRc_RRd_balance'\n",
    "nClasses_layer3=2\n",
    "layer_3='_layer3_RRc_RRd_balance'\n",
    "\n",
    "X_train=X_train_third_layer_RR_norm\n",
    "X_test=X_test_third_layer_RR_norm\n",
    "y_train=y_train_third_layer_RR\n",
    "y_test=y_test_third_layer_RR\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'auto', 'n_estimators': 550, 'min_samples_split': 7}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto', 'min_samples_split': 7, 'n_estimators': 550}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_rf(X_train,y_train, types_layer3, layer=layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.82857143 0.17142857]\n",
      " [0.22857143 0.77142857]]\n"
     ]
    }
   ],
   "source": [
    "fit_model3_RRc_RRd, ypred3_RRc_RRd, probability3_RRc_RRd, conf_mat3_RRc_RRd, misclassified3_RRc_RRd, misclassified_data3_RRc_RRd, feature_imp3_RRc_RRd=final_prediction(layer=layer_3, X_train=X_train, y_train=y_train, \\\n",
    "                     X_test= X_test, y_test=y_test,classes=classes_types_layer3, types=types_layer3, data=data, nClasses=nClasses_layer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Layer: Cepheids\n",
    "### ACEP and Cep-II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Sigma</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Period</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Mean Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>218.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>218.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.115666</td>\n",
       "      <td>0.782802</td>\n",
       "      <td>0.331901</td>\n",
       "      <td>0.062818</td>\n",
       "      <td>0.098783</td>\n",
       "      <td>0.309534</td>\n",
       "      <td>0.393477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.158825</td>\n",
       "      <td>0.093556</td>\n",
       "      <td>0.162873</td>\n",
       "      <td>0.157110</td>\n",
       "      <td>0.191026</td>\n",
       "      <td>0.159196</td>\n",
       "      <td>0.181194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.580612</td>\n",
       "      <td>0.090910</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.085699</td>\n",
       "      <td>0.131236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.028229</td>\n",
       "      <td>0.709784</td>\n",
       "      <td>0.217751</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>0.007164</td>\n",
       "      <td>0.200425</td>\n",
       "      <td>0.266496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.064691</td>\n",
       "      <td>0.784999</td>\n",
       "      <td>0.282968</td>\n",
       "      <td>0.014743</td>\n",
       "      <td>0.012276</td>\n",
       "      <td>0.260113</td>\n",
       "      <td>0.333449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.130363</td>\n",
       "      <td>0.844307</td>\n",
       "      <td>0.431071</td>\n",
       "      <td>0.024950</td>\n",
       "      <td>0.095204</td>\n",
       "      <td>0.396781</td>\n",
       "      <td>0.511494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Skew        Mean       Sigma    Kurtosis      Period   Amplitude  \\\n",
       "count  218.000000  218.000000  218.000000  218.000000  218.000000  218.000000   \n",
       "mean     0.115666    0.782802    0.331901    0.062818    0.098783    0.309534   \n",
       "std      0.158825    0.093556    0.162873    0.157110    0.191026    0.159196   \n",
       "min      0.000041    0.580612    0.090910    0.000271    0.002660    0.085699   \n",
       "25%      0.028229    0.709784    0.217751    0.007985    0.007164    0.200425   \n",
       "50%      0.064691    0.784999    0.282968    0.014743    0.012276    0.260113   \n",
       "75%      0.130363    0.844307    0.431071    0.024950    0.095204    0.396781   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "       Mean Variance  \n",
       "count     218.000000  \n",
       "mean        0.393477  \n",
       "std         0.181194  \n",
       "min         0.131236  \n",
       "25%         0.266496  \n",
       "50%         0.333449  \n",
       "75%         0.511494  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_third_layer_Cep = pd.concat([ACEP_xtrain_2, LMC_Cep_II_xtrain_2], axis=0, sort=False)\n",
    "x_test_third_layer_Cep = pd.concat([ACEP_xtest_2, LMC_Cep_II_xtest_2], axis=0, sort=False)\n",
    "\n",
    "\n",
    "# Finding the maximum of x_train. Normalisation = |X/max(X_train)| where X is the values of x's in training set and test set\n",
    "# Take the absolute values so that all is positive\n",
    "x_train_third_layer_Cep_max  = x_train_third_layer_Cep.iloc[:,0:7].max(axis=0)\n",
    "X_train_third_layer_Cep_norm = x_train_third_layer_Cep.iloc[:,0:7].divide(x_train_third_layer_Cep_max, axis=1).abs()\n",
    "\n",
    "\n",
    "X_test_third_layer_Cep_norm = x_test_third_layer_Cep.iloc[:,0:7].divide(x_train_third_layer_Cep_max, axis=1).abs()\n",
    "X_test_third_layer_Cep_norm.describe()\n",
    "\n",
    "\n",
    "y_train_third_layer_Cep = x_train_third_layer_Cep['label']\n",
    "y_test_third_layer_Cep  = x_test_third_layer_Cep['label']\n",
    "X_train_third_layer_Cep_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Third Layer - Cepheids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Section Needs to be changed each time\n",
    "classes_types_layer3=[\"ACEP\", \"Cep-II\"]\n",
    "types_layer3 ='TypeACEP_Cep-II'\n",
    "nClasses_layer3=2\n",
    "layer_3='_layer3_Cep'\n",
    "\n",
    "X_train=X_train_third_layer_Cep_norm\n",
    "X_test=X_test_third_layer_Cep_norm\n",
    "y_train=y_train_third_layer_Cep\n",
    "y_test=y_test_third_layer_Cep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'log2', 'n_estimators': 550, 'min_samples_split': 19}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 'log2', 'min_samples_split': 19, 'n_estimators': 550}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_rf(X_train,y_train, types_layer3, layer=layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.88888889 0.11111111]\n",
      " [0.27906977 0.72093023]]\n"
     ]
    }
   ],
   "source": [
    "fit_model3_Cep, ypred3_Cep, probability3_Cep, conf_mat3_Cep, misclassified3_Cep, misclassified_data3_Cep, feature_imp3_Cep=final_prediction(layer=layer_3, X_train=X_train, y_train=y_train, \\\n",
    "                     X_test= X_test, y_test=y_test,classes=classes_types_layer3, types=types_layer3, data=data, nClasses=nClasses_layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
